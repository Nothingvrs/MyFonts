"""
–°–µ—Ä–≤–∏—Å –∞–Ω–∞–ª–∏–∑–∞ —à—Ä–∏—Ñ—Ç–æ–≤ —Å –∏—Å–ø–æ–ª—å–∑–æ–≤–∞–Ω–∏–µ–º PaddleOCR –∏ OpenCV
"""

import cv2
import numpy as np
from PIL import Image
import io
import logging
from typing import Tuple, List, Dict, Any
import asyncio
from concurrent.futures import ThreadPoolExecutor

from ..models.font_models import FontCharacteristics, CyrillicFeatures
from .paddleocr_service import PaddleOCRService

logger = logging.getLogger(__name__)


class FontAnalyzer:
    """–ê–Ω–∞–ª–∏–∑–∞—Ç–æ—Ä —à—Ä–∏—Ñ—Ç–æ–≤ –Ω–∞ –æ—Å–Ω–æ–≤–µ PaddleOCR –∏ OpenCV"""
    
    def __init__(self):
        self.executor = ThreadPoolExecutor(max_workers=4)
        self.paddleocr_service = PaddleOCRService()
        
    async def analyze_image(self, image_bytes: bytes) -> FontCharacteristics:
        """–ê–Ω–∞–ª–∏–∑ –∏–∑–æ–±—Ä–∞–∂–µ–Ω–∏—è –¥–ª—è –æ–ø—Ä–µ–¥–µ–ª–µ–Ω–∏—è —Ö–∞—Ä–∞–∫—Ç–µ—Ä–∏—Å—Ç–∏–∫ —à—Ä–∏—Ñ—Ç–∞"""
        return await self._analyze_image_async(image_bytes)
    
    async def _analyze_image_async(self, image_bytes: bytes) -> FontCharacteristics:
        """–ê—Å–∏–Ω—Ö—Ä–æ–Ω–Ω—ã–π –∞–Ω–∞–ª–∏–∑ –∏–∑–æ–±—Ä–∞–∂–µ–Ω–∏—è —á–µ—Ä–µ–∑ OCR"""
        
        # –ó–∞–≥—Ä—É–∂–∞–µ–º –∏–∑–æ–±—Ä–∞–∂–µ–Ω–∏–µ
        image = self._load_image(image_bytes)
        
        # –ü—Ä–æ–≤–µ—Ä—è–µ–º –Ω–∞ –º–Ω–æ–∂–µ—Å—Ç–≤–µ–Ω–Ω—ã–µ —à—Ä–∏—Ñ—Ç—ã –ü–û–°–õ–ï –∞–Ω–∞–ª–∏–∑–∞
        logger.info("=== –ü—Ä–æ–≤–µ—Ä—è–µ–º –º–Ω–æ–∂–µ—Å—Ç–≤–µ–Ω–Ω—ã–µ —à—Ä–∏—Ñ—Ç—ã –ü–û–°–õ–ï –∞–Ω–∞–ª–∏–∑–∞ ===")
        
        # –°–Ω–∞—á–∞–ª–∞ –¥–µ–ª–∞–µ–º –∞–Ω–∞–ª–∏–∑
        logger.info("–í—ã–ø–æ–ª–Ω—è–µ–º –∞–Ω–∞–ª–∏–∑ —à—Ä–∏—Ñ—Ç–∞...")
        
        # –®–ê–ì 1: –°–Ω–∞—á–∞–ª–∞ –∏—Å–∫–ª—é—á–∞–µ–º –æ—á–µ–≤–∏–¥–Ω–æ –ù–ï-—Ç–µ–∫—Å—Ç–æ–≤—ã–µ –∏–∑–æ–±—Ä–∞–∂–µ–Ω–∏—è (—Å–º—è–≥—á–µ–Ω–Ω—ã–π)
        logger.info("=== –®–ê–ì 1: –ü—Ä–æ–≤–µ—Ä–∫–∞ –ù–ï-—Ç–µ–∫—Å—Ç–æ–≤—ã—Ö –∏–∑–æ–±—Ä–∞–∂–µ–Ω–∏–π (—Å–º—è–≥—á–µ–Ω–Ω–∞—è) ===")
        if self._is_obviously_not_text(image):
            logger.info("–†–ï–ó–£–õ–¨–¢–ê–¢ –®–ê–ì 1: –ò–∑–æ–±—Ä–∞–∂–µ–Ω–∏–µ –æ–ø—Ä–µ–¥–µ–ª–µ–Ω–æ –∫–∞–∫ –ù–ï-—Ç–µ–∫—Å—Ç–æ–≤–æ–µ")
            raise ValueError("–ù–∞ –∏–∑–æ–±—Ä–∞–∂–µ–Ω–∏–∏ –Ω–µ –æ–±–Ω–∞—Ä—É–∂–µ–Ω —Ç–µ–∫—Å—Ç –¥–ª—è –∞–Ω–∞–ª–∏–∑–∞. –ü–æ–ø—Ä–æ–±—É–π—Ç–µ –∑–∞–≥—Ä—É–∑–∏—Ç—å –∏–∑–æ–±—Ä–∞–∂–µ–Ω–∏–µ —Å —á–µ—Ç–∫–∏–º, —á–∏—Ç–∞–µ–º—ã–º —Ç–µ–∫—Å—Ç–æ–º.")
        logger.info("–†–ï–ó–£–õ–¨–¢–ê–¢ –®–ê–ì 1: –ò–∑–æ–±—Ä–∞–∂–µ–Ω–∏–µ –ø—Ä–æ—à–ª–æ –ø—Ä–æ–≤–µ—Ä–∫—É –ù–ï-—Ç–µ–∫—Å—Ç–æ–≤—ã—Ö")
        

    
    async def _analyze_image_async(self, image_bytes: bytes) -> FontCharacteristics:
        """–ê—Å–∏–Ω—Ö—Ä–æ–Ω–Ω—ã–π –∞–Ω–∞–ª–∏–∑ –∏–∑–æ–±—Ä–∞–∂–µ–Ω–∏—è —Å fallback"""
        try:
            # –ó–∞–≥—Ä—É–∂–∞–µ–º –∏–∑–æ–±—Ä–∞–∂–µ–Ω–∏–µ
            image = self._load_image(image_bytes)
            
            # –®–ê–ì 1: –ü—Ä–æ–≤–µ—Ä—è–µ–º –Ω–∞ –æ—á–µ–≤–∏–¥–Ω–æ –ù–ï-—Ç–µ–∫—Å—Ç–æ–≤—ã–µ –∏–∑–æ–±—Ä–∞–∂–µ–Ω–∏—è
            logger.info("=== –®–ê–ì 1: –ü—Ä–æ–≤–µ—Ä–∫–∞ –Ω–∞ –ù–ï-—Ç–µ–∫—Å—Ç–æ–≤—ã–µ –∏–∑–æ–±—Ä–∞–∂–µ–Ω–∏—è ===")
            if self._is_obviously_not_text(image):
                logger.info("–†–ï–ó–£–õ–¨–¢–ê–¢ –®–ê–ì 1: –ò–∑–æ–±—Ä–∞–∂–µ–Ω–∏–µ –Ω–µ —Å–æ–¥–µ—Ä–∂–∏—Ç —Ç–µ–∫—Å—Ç - –°–¢–û–ü")
                raise ValueError("–ò–∑–æ–±—Ä–∞–∂–µ–Ω–∏–µ –Ω–µ —Å–æ–¥–µ—Ä–∂–∏—Ç —á–∏—Ç–∞–µ–º—ã–π —Ç–µ–∫—Å—Ç –¥–ª—è –∞–Ω–∞–ª–∏–∑–∞")
            else:
                logger.info("–†–ï–ó–£–õ–¨–¢–ê–¢ –®–ê–ì 1: –ò–∑–æ–±—Ä–∞–∂–µ–Ω–∏–µ –º–æ–∂–µ—Ç —Å–æ–¥–µ—Ä–∂–∞—Ç—å —Ç–µ–∫—Å—Ç - –ø—Ä–æ–¥–æ–ª–∂–∞–µ–º")
            
            # –®–ê–ì 2: –ü—Ä–æ–≤–µ—Ä—è–µ–º –Ω–∞–ª–∏—á–∏–µ —Ç–µ–∫—Å—Ç–∞
            logger.info("=== –®–ê–ì 2: –ü—Ä–æ–≤–µ—Ä–∫–∞ –Ω–∞–ª–∏—á–∏—è —Ç–µ–∫—Å—Ç–∞ ===")
            if not self._detect_text_presence(image):
                logger.info("–†–ï–ó–£–õ–¨–¢–ê–¢ –®–ê–ì 2: –¢–µ–∫—Å—Ç –Ω–µ –æ–±–Ω–∞—Ä—É–∂–µ–Ω - –°–¢–û–ü")
                raise ValueError("–ù–∞ –∏–∑–æ–±—Ä–∞–∂–µ–Ω–∏–∏ –Ω–µ –æ–±–Ω–∞—Ä—É–∂–µ–Ω —á–∏—Ç–∞–µ–º—ã–π —Ç–µ–∫—Å—Ç –¥–ª—è –∞–Ω–∞–ª–∏–∑–∞")
            else:
                logger.info("–†–ï–ó–£–õ–¨–¢–ê–¢ –®–ê–ì 2: –¢–µ–∫—Å—Ç –æ–±–Ω–∞—Ä—É–∂–µ–Ω - –ø—Ä–æ–¥–æ–ª–∂–∞–µ–º")
            
            # –®–ê–ì 3: –ü—Ä–æ–≤–µ—Ä—è–µ–º –Ω–∞ –º–Ω–æ–∂–µ—Å—Ç–≤–µ–Ω–Ω—ã–µ —à—Ä–∏—Ñ—Ç—ã (—Ç–æ–ª—å–∫–æ –µ—Å–ª–∏ —Ç–µ–∫—Å—Ç –Ω–∞–π–¥–µ–Ω) - OCR –ê–ù–ê–õ–ò–ó
            logger.info("=== –®–ê–ì 3: –ü—Ä–æ–≤–µ—Ä–∫–∞ –º–Ω–æ–∂–µ—Å—Ç–≤–µ–Ω–Ω—ã—Ö —à—Ä–∏—Ñ—Ç–æ–≤ (OCR) ===")
            if await self._detect_multiple_fonts(image):
                logger.info("–†–ï–ó–£–õ–¨–¢–ê–¢ –®–ê–ì 3: –û–±–Ω–∞—Ä—É–∂–µ–Ω–æ –Ω–µ—Å–∫–æ–ª—å–∫–æ —à—Ä–∏—Ñ—Ç–æ–≤ - –°–¢–û–ü")
                raise ValueError("–ù–∞ –∏–∑–æ–±—Ä–∞–∂–µ–Ω–∏–∏ –æ–±–Ω–∞—Ä—É–∂–µ–Ω–æ –Ω–µ—Å–∫–æ–ª—å–∫–æ —Ä–∞–∑–Ω—ã—Ö —à—Ä–∏—Ñ—Ç–æ–≤. –î–ª—è —Ç–æ—á–Ω–æ–≥–æ –∞–Ω–∞–ª–∏–∑–∞ –∑–∞–≥—Ä—É–∑–∏—Ç–µ –∏–∑–æ–±—Ä–∞–∂–µ–Ω–∏–µ —Å —Ç–µ–∫—Å—Ç–æ–º –æ–¥–Ω–æ–≥–æ —à—Ä–∏—Ñ—Ç–∞.")
            logger.info("–†–ï–ó–£–õ–¨–¢–ê–¢ –®–ê–ì 3: –û–¥–∏–Ω —à—Ä–∏—Ñ—Ç - –ø—Ä–æ–¥–æ–ª–∂–∞–µ–º –∫ –∞–Ω–∞–ª–∏–∑—É")
            
            # –®–ê–ì 4: –¢–û–õ–¨–ö–û –¢–ï–ü–ï–†–¨ –¥–µ–ª–∞–µ–º –∞–Ω–∞–ª–∏–∑ —à—Ä–∏—Ñ—Ç–∞ —á–µ—Ä–µ–∑ OCR (–æ—Å–Ω–æ–≤–Ω–∞—è –æ–ø–µ—Ä–∞—Ü–∏—è)
            logger.info("=== –®–ê–ì 4: –ê–Ω–∞–ª–∏–∑ —Ö–∞—Ä–∞–∫—Ç–µ—Ä–∏—Å—Ç–∏–∫ —à—Ä–∏—Ñ—Ç–∞ –ß–ï–†–ï–ó OCR ===")
            
            # –ò–∑–≤–ª–µ–∫–∞–µ–º —Ö–∞—Ä–∞–∫—Ç–µ—Ä–∏—Å—Ç–∏–∫–∏ –¢–û–õ–¨–ö–û –∏–∑ OCR
            # –°–Ω–∞—á–∞–ª–∞ –ø–æ–ª—É—á–∞–µ–º OCR —Ä–µ–∑—É–ª—å—Ç–∞—Ç
            if not hasattr(self, 'paddleocr_service') or not self.paddleocr_service:
                logger.error("‚ùå PaddleOCR —Å–µ—Ä–≤–∏—Å –Ω–µ–¥–æ—Å—Ç—É–ø–µ–Ω!")
                raise ValueError("PaddleOCR —Å–µ—Ä–≤–∏—Å –Ω–µ–¥–æ—Å—Ç—É–ø–µ–Ω")
            
            # –ü—Ä–æ–≤–µ—Ä—è–µ–º –¥–æ—Å—Ç—É–ø–Ω–æ—Å—Ç—å PaddleOCR
            if not self.paddleocr_service.is_available():
                logger.error("‚ùå PaddleOCR –Ω–µ –∏–Ω–∏—Ü–∏–∞–ª–∏–∑–∏—Ä–æ–≤–∞–Ω!")
                raise ValueError("PaddleOCR –Ω–µ –∏–Ω–∏—Ü–∏–∞–ª–∏–∑–∏—Ä–æ–≤–∞–Ω")
            
            logger.info(f"üîç –ó–∞–ø—É—Å–∫–∞–µ–º PaddleOCR –∞–Ω–∞–ª–∏–∑ –¥–ª—è –∏–∑–æ–±—Ä–∞–∂–µ–Ω–∏—è {image.shape}")
            logger.info(f"üîç PaddleOCR –¥–æ—Å—Ç—É–ø–µ–Ω: {self.paddleocr_service.is_available()}")
            
            # –ò—Å–ø–æ–ª—å–∑—É–µ–º –ø—Ä–∞–≤–∏–ª—å–Ω—ã–π –º–µ—Ç–æ–¥ PaddleOCR
            ocr_result = await self.paddleocr_service.analyze_image(image)
            
            # –î–ï–¢–ê–õ–¨–ù–û–ï –õ–û–ì–ò–†–û–í–ê–ù–ò–ï OCR —Ä–µ–∑—É–ª—å—Ç–∞—Ç–∞
            logger.info(f"üîç PADDLEOCR –†–ï–ó–£–õ–¨–¢–ê–¢:")
            logger.info(f"  - has_text: {ocr_result.get('has_text', False)}")
            logger.info(f"  - text_content: '{ocr_result.get('text_content', '')[:50]}...'")
            logger.info(f"  - confidence: {ocr_result.get('confidence', 0.0):.3f}")
            logger.info(f"  - regions_count: {ocr_result.get('regions_count', 0)}")
            logger.info(f"  - error: {ocr_result.get('error', '–Ω–µ—Ç')}")
            
            if not ocr_result.get('has_text', False):
                logger.error(f"‚ùå OCR –Ω–µ –Ω–∞—à–µ–ª —Ç–µ–∫—Å—Ç: {ocr_result}")
                raise ValueError("OCR –Ω–µ —Å–º–æ–≥ –Ω–∞–π—Ç–∏ —Ç–µ–∫—Å—Ç –Ω–∞ –∏–∑–æ–±—Ä–∞–∂–µ–Ω–∏–∏")
            
            logger.info(f"‚úÖ OCR —É—Å–ø–µ—à–Ω–æ –Ω–∞—à–µ–ª —Ç–µ–∫—Å—Ç, –∏–∑–≤–ª–µ–∫–∞–µ–º —Ö–∞—Ä–∞–∫—Ç–µ—Ä–∏—Å—Ç–∏–∫–∏...")
            characteristics = await self._extract_characteristics_from_ocr(image, ocr_result)
            
            logger.info("‚úÖ –ê–Ω–∞–ª–∏–∑ –∑–∞–≤–µ—Ä—à–µ–Ω —É—Å–ø–µ—à–Ω–æ —á–µ—Ä–µ–∑ OCR")
            return characteristics
            
        except ValueError as logic_error:
            # –õ–æ–≥–∏—á–µ—Å–∫–∏–µ –æ—à–∏–±–∫–∏ (–Ω–µ—Ç —Ç–µ–∫—Å—Ç–∞, –º–Ω–æ–≥–æ —à—Ä–∏—Ñ—Ç–æ–≤) - –ù–ï fallback!
            logger.info(f"‚ÑπÔ∏è –õ–æ–≥–∏—á–µ—Å–∫–∏–π —Ä–µ–∑—É–ª—å—Ç–∞—Ç OCR: {str(logic_error)}")
            raise logic_error  # –ü–µ—Ä–µ–¥–∞–µ–º –æ—à–∏–±–∫—É –ø–æ–ª—å–∑–æ–≤–∞—Ç–µ–ª—é
            
        except Exception as ocr_error:
            # –¢–æ–ª—å–∫–æ —Ç–µ—Ö–Ω–∏—á–µ—Å–∫–∏–µ –æ—à–∏–±–∫–∏ OCR - fallback
            logger.error(f"‚ùå –¢–µ—Ö–Ω–∏—á–µ—Å–∫–∞—è –æ—à–∏–±–∫–∞ OCR: {str(ocr_error)}")
            logger.warning("‚ö†Ô∏è –ü–µ—Ä–µ–∫–ª—é—á–∞–µ–º—Å—è –Ω–∞ fallback –º–µ—Ç–æ–¥...")
            
            # FALLBACK: —Ç–æ–ª—å–∫–æ –ø—Ä–∏ —Ç–µ—Ö–Ω–∏—á–µ—Å–∫–∏—Ö –æ—à–∏–±–∫–∞—Ö OCR
            try:
                logger.info("=== FALLBACK: –ê–Ω–∞–ª–∏–∑ –±–µ–∑ OCR ===")
                characteristics = await self._extract_characteristics_from_full_image(image)
                logger.info("‚úÖ Fallback –∞–Ω–∞–ª–∏–∑ –∑–∞–≤–µ—Ä—à–µ–Ω —É—Å–ø–µ—à–Ω–æ")
                return characteristics
            except Exception as fallback_error:
                logger.error(f"‚ùå –û—à–∏–±–∫–∞ fallback –∞–Ω–∞–ª–∏–∑–∞: {str(fallback_error)}")
                raise ValueError(f"–ù–µ —É–¥–∞–ª–æ—Å—å –ø—Ä–æ–∞–Ω–∞–ª–∏–∑–∏—Ä–æ–≤–∞—Ç—å –∏–∑–æ–±—Ä–∞–∂–µ–Ω–∏–µ: {str(ocr_error)}")
    
    def _load_image(self, image_bytes: bytes) -> np.ndarray:
        """–ó–∞–≥—Ä—É–∑–∫–∞ –∏–∑–æ–±—Ä–∞–∂–µ–Ω–∏—è –∏–∑ –±–∞–π—Ç–æ–≤"""
        try:
            # –ò—Å–ø–æ–ª—å–∑—É–µ–º PIL –¥–ª—è –∑–∞–≥—Ä—É–∑–∫–∏
            pil_image = Image.open(io.BytesIO(image_bytes))
            
            # –ö–æ–Ω–≤–µ—Ä—Ç–∏—Ä—É–µ–º –≤ RGB –µ—Å–ª–∏ –Ω—É–∂–Ω–æ
            if pil_image.mode != 'RGB':
                pil_image = pil_image.convert('RGB')
            
            # –ö–æ–Ω–≤–µ—Ä—Ç–∏—Ä—É–µ–º –≤ numpy array (RGB –¥–ª—è PaddleOCR)
            cv_image = np.array(pil_image)  # –û—Å—Ç–∞–≤–ª—è–µ–º RGB —Ñ–æ—Ä–º–∞—Ç –¥–ª—è PaddleOCR
            
            logger.info(f"–ò–∑–æ–±—Ä–∞–∂–µ–Ω–∏–µ –∑–∞–≥—Ä—É–∂–µ–Ω–æ: {cv_image.shape}, —Ñ–æ—Ä–º–∞—Ç: RGB")
            return cv_image
            
        except Exception as e:
            logger.error(f"–û—à–∏–±–∫–∞ –∑–∞–≥—Ä—É–∑–∫–∏ –∏–∑–æ–±—Ä–∞–∂–µ–Ω–∏—è: {str(e)}")
            raise ValueError(f"–ù–µ —É–¥–∞–ª–æ—Å—å –∑–∞–≥—Ä—É–∑–∏—Ç—å –∏–∑–æ–±—Ä–∞–∂–µ–Ω–∏–µ: {str(e)}")
    
    def _is_obviously_not_text(self, image: np.ndarray) -> bool:
        """–ü—Ä–æ–≤–µ—Ä–∫–∞ –Ω–∞ –æ—á–µ–≤–∏–¥–Ω–æ –ù–ï-—Ç–µ–∫—Å—Ç–æ–≤—ã–µ –∏–∑–æ–±—Ä–∞–∂–µ–Ω–∏—è (–∏–∫–æ–Ω–∫–∏, –ø—Ä–æ—Å—Ç–∞—è –≥—Ä–∞—Ñ–∏–∫–∞)"""
        try:
            gray = cv2.cvtColor(image, cv2.COLOR_BGR2GRAY)
            
            # –ü—Ä–æ–≤–µ—Ä—è–µ–º —Ä–∞–∑–º–µ—Ä –∏–∑–æ–±—Ä–∞–∂–µ–Ω–∏—è
            height, width = gray.shape
            total_pixels = height * width
            
            # –°–ª–∏—à–∫–æ–º –º–∞–ª–µ–Ω—å–∫–∏–µ –∏–∑–æ–±—Ä–∞–∂–µ–Ω–∏—è –æ–±—ã—á–Ω–æ –Ω–µ —Å–æ–¥–µ—Ä–∂–∞—Ç —á–∏—Ç–∞–µ–º—ã–π —Ç–µ–∫—Å—Ç
            if total_pixels < 2000:  # –ú–µ–Ω–µ–µ 45x45 (–µ—â–µ –±–æ–ª–µ–µ –º—è–≥–∫–æ)
                return True
            
            # –ü—Ä–æ–≤–µ—Ä—è–µ–º –æ–¥–Ω–æ—Ä–æ–¥–Ω–æ—Å—Ç—å (–ø—Ä–æ—Å—Ç—ã–µ –∏–∫–æ–Ω–∫–∏ —á–∞—Å—Ç–æ –æ–¥–Ω–æ—Ä–æ–¥–Ω—ã)
            std_dev = np.std(gray.astype(np.float64))
            if std_dev < 1:  # –û—á–µ–Ω—å –Ω–∏–∑–∫–∞—è –≤–∞—Ä–∏–∞—Ü–∏—è - –≤–µ—Ä–æ—è—Ç–Ω–æ –ø—Ä–æ—Å—Ç–∞—è –≥—Ä–∞—Ñ–∏–∫–∞
                return True
            
            # –ü—Ä–æ–≤–µ—Ä—è–µ–º –∫–æ–ª–∏—á–µ—Å—Ç–≤–æ —É–Ω–∏–∫–∞–ª—å–Ω—ã—Ö —Ü–≤–µ—Ç–æ–≤ (—Å–ª–∏—à–∫–æ–º –º–∞–ª–æ = –ø—Ä–æ—Å—Ç–∞—è –≥—Ä–∞—Ñ–∏–∫–∞)
            unique_values = len(np.unique(gray))
            if unique_values < 3:  # –°–ª–∏—à–∫–æ–º –º–∞–ª–æ –≥—Ä–∞–¥–∞—Ü–∏–π —Å–µ—Ä–æ–≥–æ
                return True
            
            # –ü—Ä–æ–≤–µ—Ä—è–µ–º –ø—Ä–µ–æ–±–ª–∞–¥–∞–Ω–∏–µ –æ–¥–Ω–æ–≥–æ —Ü–≤–µ—Ç–∞
            hist = cv2.calcHist([gray], [0], None, [256], [0, 256])
            max_bin_ratio = np.max(hist) / total_pixels
            if max_bin_ratio > 0.95:  # –ë–æ–ª–µ–µ 95% –ø–∏–∫—Å–µ–ª–µ–π –æ–¥–Ω–æ–≥–æ —Ü–≤–µ—Ç–∞
                return True
            
            logger.info(f"–ü—Ä–æ–≤–µ—Ä–∫–∞ –ù–ï-—Ç–µ–∫—Å—Ç–∞: —Ä–∞–∑–º–µ—Ä={total_pixels}, –æ—Ç–∫–ª–æ–Ω–µ–Ω–∏–µ={std_dev:.1f}, —Ü–≤–µ—Ç–∞={unique_values}, –ø—Ä–µ–æ–±–ª–∞–¥–∞–Ω–∏–µ={max_bin_ratio:.3f}")
            return False
            
        except Exception as e:
            logger.error(f"–û—à–∏–±–∫–∞ –ø—Ä–æ–≤–µ—Ä–∫–∏ –ù–ï-—Ç–µ–∫—Å—Ç–∞: {str(e)}")
            return False  # –í —Å–ª—É—á–∞–µ –æ—à–∏–±–∫–∏ —Ä–∞–∑—Ä–µ—à–∞–µ–º –¥–∞–ª—å–Ω–µ–π—à–∏–π –∞–Ω–∞–ª–∏–∑
    
    def _detect_text_presence(self, image: np.ndarray) -> bool:
        """–£–ü–†–û–©–ï–ù–ù–û–ï –∏ –ù–ê–î–ï–ñ–ù–û–ï –æ–ø—Ä–µ–¥–µ–ª–µ–Ω–∏–µ –Ω–∞–ª–∏—á–∏—è —Ç–µ–∫—Å—Ç–∞"""
        try:
            gray = cv2.cvtColor(image, cv2.COLOR_BGR2GRAY)
            height, width = gray.shape
            total_pixels = height * width
            
            logger.info("=== –£–ü–†–û–©–ï–ù–ù–´–ô –ê–ù–ê–õ–ò–ó –¢–ï–ö–°–¢–ê ===")
            logger.info(f"–†–∞–∑–º–µ—Ä –∏–∑–æ–±—Ä–∞–∂–µ–Ω–∏—è: {width}x{height} ({total_pixels} –ø–∏–∫—Å–µ–ª–µ–π)")
            
            # –ü–†–û–°–¢–ê–Ø –ò –ù–ê–î–ï–ñ–ù–ê–Ø –õ–û–ì–ò–ö–ê:
            
            # 1. –ï—Å–ª–∏ –∏–∑–æ–±—Ä–∞–∂–µ–Ω–∏–µ —Å–ª–∏—à–∫–æ–º –º–∞–ª–µ–Ω—å–∫–æ–µ - —Å–∫–æ—Ä–µ–µ –≤—Å–µ–≥–æ –∏–∫–æ–Ω–∫–∞
            if total_pixels < 2000:  # –ú–µ–Ω—å—à–µ 45x45
                logger.info("–°–ª–∏—à–∫–æ–º –º–∞–ª–µ–Ω—å–∫–æ–µ –∏–∑–æ–±—Ä–∞–∂–µ–Ω–∏–µ - –≤–µ—Ä–æ—è—Ç–Ω–æ –∏–∫–æ–Ω–∫–∞")
                return False
            
            # 2. –ï—Å–ª–∏ –∏–∑–æ–±—Ä–∞–∂–µ–Ω–∏–µ —Å–ª–∏—à–∫–æ–º –æ–¥–Ω–æ—Ä–æ–¥–Ω–æ–µ - –≤–µ—Ä–æ—è—Ç–Ω–æ –ø—Ä–æ—Å—Ç–∞—è –≥—Ä–∞—Ñ–∏–∫–∞
            std_dev = np.std(gray.astype(np.float64))
            if std_dev < 5:
                logger.info(f"–°–ª–∏—à–∫–æ–º –æ–¥–Ω–æ—Ä–æ–¥–Ω–æ–µ –∏–∑–æ–±—Ä–∞–∂–µ–Ω–∏–µ (std={std_dev:.1f}) - –≤–µ—Ä–æ—è—Ç–Ω–æ –ø—Ä–æ—Å—Ç–∞—è –≥—Ä–∞—Ñ–∏–∫–∞")
                return False
            
            # 3. –ï—Å–ª–∏ –∏–∑–æ–±—Ä–∞–∂–µ–Ω–∏–µ –∏–º–µ–µ—Ç —Ä–∞–∑—É–º–Ω—ã–π —Ä–∞–∑–º–µ—Ä –ò –µ—Å—Ç—å –≤–∞—Ä–∏–∞—Ü–∏–∏ - —Å–∫–æ—Ä–µ–µ –≤—Å–µ–≥–æ –µ—Å—Ç—å —Ç–µ–∫—Å—Ç
            if total_pixels >= 2000 and std_dev >= 5:
                logger.info(f"–†–∞–∑—É–º–Ω—ã–π —Ä–∞–∑–º–µ—Ä ({total_pixels}) + –≤–∞—Ä–∏–∞—Ü–∏–∏ ({std_dev:.1f}) = –ï–°–¢–¨ –¢–ï–ö–°–¢")
                return True
            
            # 4. –î–ª—è –æ—Å—Ç–∞–ª—å–Ω—ã—Ö —Å–ª—É—á–∞–µ–≤ - —Ç–æ–∂–µ —Å—á–∏—Ç–∞–µ–º —á—Ç–æ –µ—Å—Ç—å —Ç–µ–∫—Å—Ç (–æ—á–µ–Ω—å –ª–∏–±–µ—Ä–∞–ª—å–Ω–æ)
            logger.info("–ü–æ —É–º–æ–ª—á–∞–Ω–∏—é —Å—á–∏—Ç–∞–µ–º —á—Ç–æ —Ç–µ–∫—Å—Ç –µ—Å—Ç—å")
            return True
            
        except Exception as e:
            logger.error(f"–û—à–∏–±–∫–∞ –æ–ø—Ä–µ–¥–µ–ª–µ–Ω–∏—è —Ç–µ–∫—Å—Ç–∞: {str(e)}")
            # –í —Å–ª—É—á–∞–µ –æ—à–∏–±–∫–∏ - —Å—á–∏—Ç–∞–µ–º —á—Ç–æ —Ç–µ–∫—Å—Ç –µ—Å—Ç—å (–±–µ–∑–æ–ø–∞—Å–Ω—ã–π –ø–æ–¥—Ö–æ–¥)
            return True
    
    def _legacy_text_detection(self, gray: np.ndarray) -> bool:
        """–°—Ç–∞—Ä—ã–π –º–µ—Ç–æ–¥ –æ–ø—Ä–µ–¥–µ–ª–µ–Ω–∏—è —Ç–µ–∫—Å—Ç–∞ (fallback)"""
        try:
            # –ü—Ä–∏–º–µ–Ω—è–µ–º —Ñ–∏–ª—å—Ç—Ä –¥–ª—è –≤—ã–¥–µ–ª–µ–Ω–∏—è —Ç–µ–∫—Å—Ç–∞
            edges = cv2.Canny(gray, 30, 120)  # –ë–æ–ª–µ–µ –º—è–≥–∫–∏–µ –ø–æ—Ä–æ–≥–∏
            
            # –ò—â–µ–º –∫–æ–Ω—Ç—É—Ä—ã
            contours, _ = cv2.findContours(edges, cv2.RETR_EXTERNAL, cv2.CHAIN_APPROX_SIMPLE)
            
            # –ê–Ω–∞–ª–∏–∑–∏—Ä—É–µ–º –∫–æ–Ω—Ç—É—Ä—ã –Ω–∞ –ø—Ä–µ–¥–º–µ—Ç —Ç–µ–∫—Å—Ç–æ–≤—ã—Ö —Ä–µ–≥–∏–æ–Ω–æ–≤
            text_like_contours = 0
            large_contours = 0
            
            for contour in contours:
                area = cv2.contourArea(contour)
                if area > 50:  # –†–∞—Å—à–∏—Ä—è–µ–º –¥–∏–∞–ø–∞–∑–æ–Ω —Ä–∞–∑–º–µ—Ä–æ–≤
                    x, y, w, h = cv2.boundingRect(contour)
                    aspect_ratio = w / h if h > 0 else 0
                    
                    # –ë–æ–ª–µ–µ –≥–∏–±–∫–∏–µ –∫—Ä–∏—Ç–µ—Ä–∏–∏ –¥–ª—è –±—É–∫–≤
                    if 0.1 < aspect_ratio < 5.0 and area < 10000:
                        text_like_contours += 1
                        
                    # –£—á–∏—Ç—ã–≤–∞–µ–º –∫—Ä—É–ø–Ω—ã–µ —Ç–µ–∫—Å—Ç–æ–≤—ã–µ —ç–ª–µ–º–µ–Ω—Ç—ã
                    if area > 1000:
                        large_contours += 1
            
            # –ê–Ω–∞–ª–∏–∑–∏—Ä—É–µ–º –ø–ª–æ—Ç–Ω–æ—Å—Ç—å —Ç–µ–º–Ω—ã—Ö –ø–∏–∫—Å–µ–ª–µ–π (–±–æ–ª–µ–µ –≥–∏–±–∫–æ)
            dark_pixels = np.sum(gray < 128)  # –ü–æ–≤—ã—à–∞–µ–º –ø–æ—Ä–æ–≥
            total_pixels = gray.shape[0] * gray.shape[1]
            dark_ratio = dark_pixels / total_pixels
            
            # –ê–Ω–∞–ª–∏–∑–∏—Ä—É–µ–º –∫–æ–Ω—Ç—Ä–∞—Å—Ç–Ω–æ—Å—Ç—å
            contrast = np.std(gray.astype(np.float64))
            
            # –ú–ê–ö–°–ò–ú–ê–õ–¨–ù–û –º—è–≥–∫–∏–µ —É—Å–ª–æ–≤–∏—è –æ–ø—Ä–µ–¥–µ–ª–µ–Ω–∏—è —Ç–µ–∫—Å—Ç–∞
            has_text = (
                (text_like_contours >= 1 or large_contours >= 1 or contrast > 10) and  # –ï—â–µ –±–æ–ª–µ–µ –≥–∏–±–∫–æ
                0.001 < dark_ratio < 0.99 and                         # –ü—Ä–∞–∫—Ç–∏—á–µ—Å–∫–∏ –ª—é–±–æ–π –¥–∏–∞–ø–∞–∑–æ–Ω
                contrast > 2                                          # –ú–∏–Ω–∏–º–∞–ª—å–Ω–∞—è –∫–æ–Ω—Ç—Ä–∞—Å—Ç–Ω–æ—Å—Ç—å
            )
            
            logger.info(f"Legacy –∞–Ω–∞–ª–∏–∑: –∫–æ–Ω—Ç—É—Ä—ã={text_like_contours}, –∫—Ä—É–ø–Ω—ã–µ={large_contours}, —Ç–µ–º–Ω—ã–µ –ø–∏–∫—Å–µ–ª–∏={dark_ratio:.3f}, –∫–æ–Ω—Ç—Ä–∞—Å—Ç–Ω–æ—Å—Ç—å={contrast:.1f}, —Ä–µ–∑—É–ª—å—Ç–∞—Ç={has_text}")
            return has_text
            
        except Exception as e:
            logger.error(f"–û—à–∏–±–∫–∞ legacy –∞–Ω–∞–ª–∏–∑–∞: {str(e)}")
            return False
    
    def _detect_potential_text(self, image: np.ndarray) -> bool:
        """–î–æ–ø–æ–ª–Ω–∏—Ç–µ–ª—å–Ω–∞—è –ø—Ä–æ–≤–µ—Ä–∫–∞ –Ω–∞ –Ω–∞–ª–∏—á–∏–µ –ø–æ—Ç–µ–Ω—Ü–∏–∞–ª—å–Ω–æ–≥–æ —Ç–µ–∫—Å—Ç–∞ (–ª–æ–≥–æ—Ç–∏–ø—ã, —Å—Ç–∏–ª–∏–∑–æ–≤–∞–Ω–Ω—ã–π —Ç–µ–∫—Å—Ç)"""
        try:
            gray = cv2.cvtColor(image, cv2.COLOR_BGR2GRAY)
            
            # –ü—Ä–æ–≤–µ—Ä—è–µ–º –æ–±—â—É—é –∫–æ–Ω—Ç—Ä–∞—Å—Ç–Ω–æ—Å—Ç—å
            contrast = np.std(gray.astype(np.float64))
            
            # –ü—Ä–æ–≤–µ—Ä—è–µ–º –Ω–∞–ª–∏—á–∏–µ —á–µ—Ç–∫–∏—Ö –≥—Ä–∞–Ω–∏—Ü
            edges = cv2.Canny(gray, 20, 100)
            edge_density = np.sum(edges > 0) / (edges.shape[0] * edges.shape[1])
            
            # –ü—Ä–æ–≤–µ—Ä—è–µ–º —Ä–∞–∑–Ω–æ–æ–±—Ä–∞–∑–∏–µ –∏–Ω—Ç–µ–Ω—Å–∏–≤–Ω–æ—Å—Ç–µ–π
            hist = cv2.calcHist([gray], [0], None, [256], [0, 256])
            non_zero_bins = np.count_nonzero(hist)
            
            # –ò—â–µ–º —Ç–µ–∫—Å—Ç–æ–ø–æ–¥–æ–±–Ω—ã–µ —Å—Ç—Ä—É–∫—Ç—É—Ä—ã –±–æ–ª–µ–µ —Å—Ç—Ä–æ–≥–æ
            contours, _ = cv2.findContours(edges, cv2.RETR_EXTERNAL, cv2.CHAIN_APPROX_SIMPLE)
            
            text_like_shapes = 0
            for contour in contours:
                area = cv2.contourArea(contour)
                if 200 < area < 8000:  # –†–∞–∑–º–µ—Ä—ã —Ö–∞—Ä–∞–∫—Ç–µ—Ä–Ω—ã–µ –¥–ª—è –±—É–∫–≤/—Å–ª–æ–≤
                    x, y, w, h = cv2.boundingRect(contour)
                    aspect_ratio = w / h if h > 0 else 0
                    
                    # –ü—Ä–æ–≤–µ—Ä—è–µ–º —á—Ç–æ —ç—Ç–æ –ø–æ—Ö–æ–∂–µ –Ω–∞ –±—É–∫–≤—É –∏–ª–∏ —Å–ª–æ–≤–æ
                    if 0.3 < aspect_ratio < 4.0:  # –†–∞–∑—É–º–Ω—ã–µ –ø—Ä–æ–ø–æ—Ä—Ü–∏–∏ —Ç–µ–∫—Å—Ç–∞
                        # –î–æ–ø–æ–ª–Ω–∏—Ç–µ–ª—å–Ω–∞—è –ø—Ä–æ–≤–µ—Ä–∫–∞ –Ω–∞ "—Ç–µ–∫—Å—Ç–æ–≤–æ—Å—Ç—å"
                        perimeter = cv2.arcLength(contour, True)
                        if perimeter > 0:
                            circularity = 4 * np.pi * area / (perimeter * perimeter)
                            # –¢–µ–∫—Å—Ç –æ–±—ã—á–Ω–æ –Ω–µ –æ—á–µ–Ω—å –∫—Ä—É–≥–ª—ã–π
                            if circularity < 0.7:
                                text_like_shapes += 1
            
            # –ú–ê–ö–°–ò–ú–ê–õ–¨–ù–û –º—è–≥–∫–∏–µ —É—Å–ª–æ–≤–∏—è –¥–ª—è –ø–æ—Ç–µ–Ω—Ü–∏–∞–ª—å–Ω–æ–≥–æ —Ç–µ–∫—Å—Ç–∞
            has_potential_text = (
                contrast > 8 and                     # –ï—â–µ –Ω–∏–∂–µ –∫–æ–Ω—Ç—Ä–∞—Å—Ç–Ω–æ—Å—Ç—å
                edge_density > 0.002 and            # –ï—â–µ –Ω–∏–∂–µ —Ç—Ä–µ–±–æ–≤–∞–Ω–∏—è –∫ –≥—Ä–∞–Ω–∏—Ü–∞–º
                non_zero_bins > 5 and               # –ï—â–µ –Ω–∏–∂–µ —Ä–∞–∑–Ω–æ–æ–±—Ä–∞–∑–∏–µ —Ç–æ–Ω–æ–≤
                text_like_shapes >= 1               # –ú–∏–Ω–∏–º—É–º 1 —Ç–µ–∫—Å—Ç–æ–ø–æ–¥–æ–±–Ω–∞—è —Ñ–æ—Ä–º–∞
            )
            
            logger.info(f"–î–æ–ø–æ–ª–Ω–∏—Ç–µ–ª—å–Ω–∞—è –ø—Ä–æ–≤–µ—Ä–∫–∞: –∫–æ–Ω—Ç—Ä–∞—Å—Ç–Ω–æ—Å—Ç—å={contrast:.1f}, –≥—Ä–∞–Ω–∏—Ü—ã={edge_density:.4f}, —Ç–æ–Ω–∞={non_zero_bins}, —Ñ–æ—Ä–º—ã={text_like_shapes}, —Ä–µ–∑—É–ª—å—Ç–∞—Ç={has_potential_text}")
            return has_potential_text
            
        except Exception as e:
            logger.error(f"–û—à–∏–±–∫–∞ –¥–æ–ø–æ–ª–Ω–∏—Ç–µ–ª—å–Ω–æ–π –ø—Ä–æ–≤–µ—Ä–∫–∏ —Ç–µ–∫—Å—Ç–∞: {str(e)}")
            return False  # –í —Å–ª—É—á–∞–µ –æ—à–∏–±–∫–∏ –ù–ï —Ä–∞–∑—Ä–µ—à–∞–µ–º –∞–Ω–∞–ª–∏–∑
    
    async def _detect_multiple_fonts(self, image: np.ndarray) -> bool:
        """OCR-–¥–µ—Ç–µ–∫—Ü–∏—è –º–Ω–æ–∂–µ—Å—Ç–≤–µ–Ω–Ω—ã—Ö —à—Ä–∏—Ñ—Ç–æ–≤ - –¢–û–õ–¨–ö–û —á–µ—Ä–µ–∑ PaddleOCR"""
        try:
            logger.info("=== OCR –ê–ù–ê–õ–ò–ó –ú–ù–û–ñ–ï–°–¢–í–ï–ù–ù–´–• –®–†–ò–§–¢–û–í ===")
            
            if not hasattr(self, 'paddleocr_service') or not self.paddleocr_service:
                logger.warning("PaddleOCR —Å–µ—Ä–≤–∏—Å –Ω–µ–¥–æ—Å—Ç—É–ø–µ–Ω")
                return False
            
            # –ü–æ–ª—É—á–∞–µ–º —Ä–µ–∑—É–ª—å—Ç–∞—Ç—ã OCR
            ocr_result = await self.paddleocr_service.analyze_image(image)
            
            if not ocr_result.get('has_text', False):
                logger.info("üìä –¢–µ–∫—Å—Ç –Ω–µ –Ω–∞–π–¥–µ–Ω - –ù–ï –ê–ù–ê–õ–ò–ó–ò–†–£–ï–ú")
                return False
            
            text_content = ocr_result.get('text_content', '').strip()
            regions_count = ocr_result.get('regions_count', 0)
            ocr_boxes = ocr_result.get('ocr_boxes', [])
            
            logger.info(f"üìä OCR —Ä–µ–∑—É–ª—å—Ç–∞—Ç: '{text_content}' ({regions_count} —Ä–µ–≥–∏–æ–Ω–æ–≤)")
            
            # –ê–Ω–∞–ª–∏–∑–∏—Ä—É–µ–º —Ç–µ–∫—Å—Ç
            words = text_content.split()
            word_count = len(words)
            
            # –ü–†–û–°–¢–´–ï –°–õ–£–ß–ê–ò - –æ–¥–∏–Ω —à—Ä–∏—Ñ—Ç
            if word_count <= 2:  # 1-2 —Å–ª–æ–≤–∞
                logger.info(f"üìä –ú–∞–ª–æ —Å–ª–æ–≤ ({word_count}) - –û–î–ò–ù —à—Ä–∏—Ñ—Ç")
                return False
            
            if regions_count < 4:  # –ú–∞–ª–æ —Ä–µ–≥–∏–æ–Ω–æ–≤
                logger.info(f"üìä –ú–∞–ª–æ —Ä–µ–≥–∏–æ–Ω–æ–≤ ({regions_count}) - –û–î–ò–ù —à—Ä–∏—Ñ—Ç")
                return False
            
            # –ê–ù–ê–õ–ò–ó –°–û–î–ï–†–ñ–ò–ú–û–ì–û —á–µ—Ä–µ–∑ OCR
            # –ò—â–µ–º –ø—Ä–∏–∑–Ω–∞–∫–∏ —Ä–∞–∑–Ω—ã—Ö —Ç–∏–ø–æ–≤ —Ç–µ–∫—Å—Ç–∞
            has_title = any(len(word) > 4 and word.isupper() for word in words)
            has_normal_text = any(len(word) > 3 and not word.isupper() for word in words)
            has_numbers = any(char.isdigit() for char in text_content)
            has_special_words = any(word.lower() in ['—Å–∫–∏–¥–∫–∞', '—Ü–µ–Ω–∞', '—Ä—É–±–ª—å', '%', '—Ä—É–±', '—Ä–∞—Å–ø—Ä–æ–¥–∞–∂–∞'] for word in words)
            
            logger.info(f"üìä –ê–Ω–∞–ª–∏–∑ —Å–æ–¥–µ—Ä–∂–∏–º–æ–≥–æ: –∑–∞–≥–æ–ª–æ–≤–æ–∫={has_title}, —Ç–µ–∫—Å—Ç={has_normal_text}, —Ü–∏—Ñ—Ä—ã={has_numbers}, —Å–ø–µ—Ü.—Å–ª–æ–≤–∞={has_special_words}")
            
            # –ê–ù–ê–õ–ò–ó –†–ê–ó–ú–ï–†–û–í –ß–ï–†–ï–ó OCR BOXES
            height_ratio = 1.0  # –ü–æ —É–º–æ–ª—á–∞–Ω–∏—é
            area_ratio = 1.0    # –ü–æ —É–º–æ–ª—á–∞–Ω–∏—é
            
            if len(ocr_boxes) >= 4:
                # –ê–Ω–∞–ª–∏–∑–∏—Ä—É–µ–º —Ä–∞–∑–º–µ—Ä—ã bounding boxes –∏–∑ OCR
                heights = []
                areas = []
                
                for box_info in ocr_boxes:
                    if isinstance(box_info, list) and len(box_info) >= 2:
                        box = box_info[0]  # –∫–æ–æ—Ä–¥–∏–Ω–∞—Ç—ã
                        if isinstance(box, list) and len(box) >= 4:
                            # –í—ã—á–∏—Å–ª—è–µ–º —Ä–∞–∑–º–µ—Ä—ã box
                            x_coords = [point[0] for point in box]
                            y_coords = [point[1] for point in box]
                            
                            width = max(x_coords) - min(x_coords)
                            height = max(y_coords) - min(y_coords)
                            
                            heights.append(height)
                            areas.append(width * height)
                
                if len(heights) >= 2:
                    height_ratio = max(heights) / min(heights) if min(heights) > 0 else 1
                    area_ratio = max(areas) / min(areas) if min(areas) > 0 else 1
                    
                    logger.info(f"üìä OCR —Ä–∞–∑–º–µ—Ä—ã: –≤—ã—Å–æ—Ç–∞={height_ratio:.1f}, –ø–ª–æ—â–∞–¥—å={area_ratio:.1f}")
            
            # –£–õ–£–ß–®–ï–ù–ù–´–ï –ö–†–ò–¢–ï–†–ò–ò –ú–ù–û–ñ–ï–°–¢–í–ï–ù–ù–´–• –®–†–ò–§–¢–û–í (–±–æ–ª–µ–µ —á—É–≤—Å—Ç–≤–∏—Ç–µ–ª—å–Ω—ã–µ):
            
            # 1. –ü—Ä–æ—Å—Ç—ã–µ —Å–ª—É—á–∞–∏ - —Ç–æ—á–Ω–æ –û–î–ò–ù —à—Ä–∏—Ñ—Ç
            if word_count <= 2 and regions_count <= 3:
                logger.info("üìä –ü—Ä–æ—Å—Ç–æ–π —Å–ª—É—á–∞–π: –æ—á–µ–Ω—å –º–∞–ª–æ —Å–ª–æ–≤ –∏ —Ä–µ–≥–∏–æ–Ω–æ–≤ - –û–î–ò–ù —à—Ä–∏—Ñ—Ç")
                return False
            
            # 2. –°—Ä–µ–¥–Ω—è—è —Å–ª–æ–∂–Ω–æ—Å—Ç—å - –∞–Ω–∞–ª–∏–∑–∏—Ä—É–µ–º –±–æ–ª–µ–µ –¥–µ—Ç–∞–ª—å–Ω–æ
            if word_count <= 6 and regions_count <= 8:
                # –ü—Ä–æ–≤–µ—Ä—è–µ–º —Å–æ–æ—Ç–Ω–æ—à–µ–Ω–∏–µ —Ä–∞–∑–º–µ—Ä–æ–≤ - –µ—Å–ª–∏ –Ω–µ–±–æ–ª—å—à–æ–µ, —Ç–æ –æ–¥–∏–Ω —à—Ä–∏—Ñ—Ç
                if height_ratio <= 2.0 and area_ratio <= 6.0:
                    logger.info("üìä –°—Ä–µ–¥–Ω—è—è —Å–ª–æ–∂–Ω–æ—Å—Ç—å: —Ä–∞–∑–º–µ—Ä—ã —Å—Ç–∞–±–∏–ª—å–Ω—ã–µ - –û–î–ò–ù —à—Ä–∏—Ñ—Ç")
                    return False
                # –ï—Å–ª–∏ –µ—Å—Ç—å —è–≤–Ω—ã–µ –ø—Ä–∏–∑–Ω–∞–∫–∏ –∑–∞–≥–æ–ª–æ–≤–∫–∞ + —Ç–µ–∫—Å—Ç–∞
                elif has_title and has_normal_text and height_ratio > 2.0:
                    logger.info("‚úÖ –ú–ù–û–ñ–ï–°–¢–í–ï–ù–ù–´–ï –®–†–ò–§–¢–´: –∑–∞–≥–æ–ª–æ–≤–æ–∫ + —Ç–µ–∫—Å—Ç + –∑–∞–º–µ—Ç–Ω–∞—è —Ä–∞–∑–Ω–∏—Ü–∞ —Ä–∞–∑–º–µ—Ä–æ–≤")
                    return True
                else:
                    logger.info("üìä –°—Ä–µ–¥–Ω—è—è —Å–ª–æ–∂–Ω–æ—Å—Ç—å: –Ω–µ–æ–ø—Ä–µ–¥–µ–ª–µ–Ω–Ω–æ - —Å—á–∏—Ç–∞–µ–º –û–î–ò–ù —à—Ä–∏—Ñ—Ç")
                    return False
            
            # 3. –°–ª–æ–∂–Ω—ã–µ —Å–ª—É—á–∞–∏ - –º–Ω–æ–≥–æ —Ç–µ–∫—Å—Ç–∞
            if word_count > 6 or regions_count > 8:
                # –ï—Å–ª–∏ –æ—á–µ–Ω—å –±–æ–ª—å—à–∞—è —Ä–∞–∑–Ω–∏—Ü–∞ –≤ —Ä–∞–∑–º–µ—Ä–∞—Ö - —Ç–æ—á–Ω–æ —Ä–∞–∑–Ω—ã–µ —à—Ä–∏—Ñ—Ç—ã
                if height_ratio > 3.0 and area_ratio > 8.0:
                    logger.info("‚úÖ –ú–ù–û–ñ–ï–°–¢–í–ï–ù–ù–´–ï –®–†–ò–§–¢–´: –±–æ–ª—å—à–∞—è —Ä–∞–∑–Ω–∏—Ü–∞ –≤ —Ä–∞–∑–º–µ—Ä–∞—Ö")
                    return True
                # –ï—Å–ª–∏ –µ—Å—Ç—å –∑–∞–≥–æ–ª–æ–≤–æ–∫ + –º–Ω–æ–≥–æ —Ç–µ–∫—Å—Ç–∞ + —Å—Ä–µ–¥–Ω—è—è —Ä–∞–∑–Ω–∏—Ü–∞
                elif has_title and has_normal_text and height_ratio > 1.8 and word_count >= 8:
                    logger.info("‚úÖ –ú–ù–û–ñ–ï–°–¢–í–ï–ù–ù–´–ï –®–†–ò–§–¢–´: –∑–∞–≥–æ–ª–æ–≤–æ–∫ + –º–Ω–æ–≥–æ —Ç–µ–∫—Å—Ç–∞ + —Ä–∞–∑–Ω—ã–µ —Ä–∞–∑–º–µ—Ä—ã")
                    return True
                # –ï—Å–ª–∏ –ø—Ä–æ—Å—Ç–æ –º–Ω–æ–≥–æ —Ç–µ–∫—Å—Ç–∞ —Å —É–º–µ—Ä–µ–Ω–Ω—ã–º–∏ —Ä–∞–∑–ª–∏—á–∏—è–º–∏
                elif height_ratio > 2.5 and regions_count >= 12:
                    logger.info("‚úÖ –ú–ù–û–ñ–ï–°–¢–í–ï–ù–ù–´–ï –®–†–ò–§–¢–´: –º–Ω–æ–≥–æ —Ä–µ–≥–∏–æ–Ω–æ–≤ + –∑–∞–º–µ—Ç–Ω–∞—è —Ä–∞–∑–Ω–∏—Ü–∞ —Ä–∞–∑–º–µ—Ä–æ–≤")
                    return True
                # –î–æ–ø–æ–ª–Ω–∏—Ç–µ–ª—å–Ω–∞—è –ø—Ä–æ–≤–µ—Ä–∫–∞: –µ—Å–ª–∏ –µ—Å—Ç—å —Ü–∏—Ñ—Ä—ã + —Ç–µ–∫—Å—Ç + —Ä–∞–∑–Ω—ã–µ —Ä–∞–∑–º–µ—Ä—ã
                elif has_numbers and has_normal_text and height_ratio > 2.2:
                    logger.info("‚úÖ –ú–ù–û–ñ–ï–°–¢–í–ï–ù–ù–´–ï –®–†–ò–§–¢–´: —Ü–∏—Ñ—Ä—ã + —Ç–µ–∫—Å—Ç + —Ä–∞–∑–Ω—ã–µ —Ä–∞–∑–º–µ—Ä—ã")
                    return True
                else:
                    logger.info("üìä –°–ª–æ–∂–Ω—ã–π —Å–ª—É—á–∞–π: —Ä–∞–∑–ª–∏—á–∏—è –Ω–µ –∫—Ä–∏—Ç–∏—á–Ω—ã–µ - –û–î–ò–ù —à—Ä–∏—Ñ—Ç")
                    return False
            
            # –í–æ –≤—Å–µ—Ö –æ—Å—Ç–∞–ª—å–Ω—ã—Ö —Å–ª—É—á–∞—è—Ö - –æ–¥–∏–Ω —à—Ä–∏—Ñ—Ç
            logger.info("üìä –û–ø—Ä–µ–¥–µ–ª–µ–Ω–æ –∫–∞–∫ –û–î–ò–ù —à—Ä–∏—Ñ—Ç")
            return False
            
        except Exception as e:
            logger.error(f"–û—à–∏–±–∫–∞ OCR-–æ–ø—Ä–µ–¥–µ–ª–µ–Ω–∏—è –º–Ω–æ–∂–µ—Å—Ç–≤–µ–Ω–Ω—ã—Ö —à—Ä–∏—Ñ—Ç–æ–≤: {str(e)}")
            # –ü—Ä–∏ –æ—à–∏–±–∫–µ —Å—á–∏—Ç–∞–µ–º –æ–¥–∏–Ω —à—Ä–∏—Ñ—Ç (–±–µ–∑–æ–ø–∞—Å–Ω–æ)
            return False
    
    def _get_ocr_based_characteristics(self, ocr_result: dict) -> dict:
        """–ò–∑–≤–ª–µ—á–µ–Ω–∏–µ —Ö–∞—Ä–∞–∫—Ç–µ—Ä–∏—Å—Ç–∏–∫ –¢–û–õ–¨–ö–û –∏–∑ OCR —Ä–µ–∑—É–ª—å—Ç–∞—Ç–æ–≤"""
        try:
            logger.info("=== –ò–ó–í–õ–ï–ß–ï–ù–ò–ï –•–ê–†–ê–ö–¢–ï–†–ò–°–¢–ò–ö –ò–ó OCR ===")
            
            text_content = ocr_result.get('text_content', '').strip()
            regions_count = ocr_result.get('regions_count', 0)
            ocr_boxes = ocr_result.get('ocr_boxes', [])
            
            # –ê–Ω–∞–ª–∏–∑ —Ç–µ–∫—Å—Ç–∞
            words = text_content.split()
            word_count = len(words)
            avg_word_length = np.mean([len(word) for word in words]) if words else 0
            
            # –ê–Ω–∞–ª–∏–∑ —Ä–∞–∑–º–µ—Ä–æ–≤ –∏–∑ OCR boxes
            heights = []
            widths = []
            areas = []
            
            for box_info in ocr_boxes:
                if isinstance(box_info, list) and len(box_info) >= 2:
                    box = box_info[0]  # –∫–æ–æ—Ä–¥–∏–Ω–∞—Ç—ã
                    if isinstance(box, list) and len(box) >= 4:
                        # –í—ã—á–∏—Å–ª—è–µ–º —Ä–∞–∑–º–µ—Ä—ã box
                        x_coords = [point[0] for point in box]
                        y_coords = [point[1] for point in box]
                        
                        width = max(x_coords) - min(x_coords)
                        height = max(y_coords) - min(y_coords)
                        
                        heights.append(height)
                        widths.append(width)
                        areas.append(width * height)
            
            # –•–∞—Ä–∞–∫—Ç–µ—Ä–∏—Å—Ç–∏–∫–∏ –Ω–∞ –æ—Å–Ω–æ–≤–µ OCR –¥–∞–Ω–Ω—ã—Ö
            characteristics = {
                'text_length': len(text_content),
                'word_count': word_count,
                'regions_count': regions_count,
                'avg_word_length': avg_word_length,
                'avg_height': np.mean(heights) if heights else 20.0,
                'avg_width': np.mean(widths) if widths else 100.0,
                'avg_area': np.mean(areas) if areas else 2000.0,
                'height_variance': np.var(heights) if len(heights) > 1 else 0.0,
                'width_variance': np.var(widths) if len(widths) > 1 else 0.0,
                'has_uppercase': any(c.isupper() for c in text_content),
                'has_lowercase': any(c.islower() for c in text_content),
                'has_numbers': any(c.isdigit() for c in text_content),
                'has_cyrillic': any(ord(c) >= 1040 and ord(c) <= 1103 for c in text_content),
                'text_density': word_count / max(regions_count, 1)  # —Å–ª–æ–≤ –Ω–∞ —Ä–µ–≥–∏–æ–Ω
            }
            
            logger.info(f"OCR —Ö–∞—Ä–∞–∫—Ç–µ—Ä–∏—Å—Ç–∏–∫–∏: {characteristics}")
            return characteristics
            
        except Exception as e:
            logger.error(f"–û—à–∏–±–∫–∞ –∏–∑–≤–ª–µ—á–µ–Ω–∏—è OCR —Ö–∞—Ä–∞–∫—Ç–µ—Ä–∏—Å—Ç–∏–∫: {str(e)}")
            return self._get_default_ocr_characteristics()
    
    def _get_default_ocr_characteristics(self) -> dict:
        """OCR —Ö–∞—Ä–∞–∫—Ç–µ—Ä–∏—Å—Ç–∏–∫–∏ –ø–æ —É–º–æ–ª—á–∞–Ω–∏—é"""
        return {
            'text_length': 0,
            'word_count': 0,
            'regions_count': 0,
            'avg_word_length': 0,
            'avg_height': 20.0,
            'avg_width': 100.0,
            'avg_area': 2000.0,
            'height_variance': 0.0,
            'width_variance': 0.0,
            'has_uppercase': False,
            'has_lowercase': False,
            'has_numbers': False,
            'has_cyrillic': False,
            'text_density': 0.0
        }
    
    def _binarize_image(self, gray: np.ndarray) -> np.ndarray:
        """–ë–∏–Ω–∞—Ä–∏–∑–∞—Ü–∏—è –∏–∑–æ–±—Ä–∞–∂–µ–Ω–∏—è"""
        # –ò—Å–ø–æ–ª—å–∑—É–µ–º –∞–¥–∞–ø—Ç–∏–≤–Ω—É—é –±–∏–Ω–∞—Ä–∏–∑–∞—Ü–∏—é –¥–ª—è –ª—É—á—à–µ–≥–æ —Ä–µ–∑—É–ª—å—Ç–∞—Ç–∞
        binary = cv2.adaptiveThreshold(
            gray, 255, cv2.ADAPTIVE_THRESH_GAUSSIAN_C, cv2.THRESH_BINARY, 11, 2
        )
        return binary
    
    async def _extract_characteristics_from_ocr(self, image: np.ndarray, ocr_result: dict) -> FontCharacteristics:
        """–ò–∑–≤–ª–µ—á–µ–Ω–∏–µ —Ö–∞—Ä–∞–∫—Ç–µ—Ä–∏—Å—Ç–∏–∫ —à—Ä–∏—Ñ—Ç–∞ –¢–û–õ–¨–ö–û –∏–∑ OCR"""
        
        logger.info("=== –ò–ó–í–õ–ï–ß–ï–ù–ò–ï –•–ê–†–ê–ö–¢–ï–†–ò–°–¢–ò–ö –ß–ï–†–ï–ó OCR ===")
        
        # OCR —Ä–µ–∑—É–ª—å—Ç–∞—Ç —É–∂–µ –ø–æ–ª—É—á–µ–Ω –≤ –≤—ã–∑—ã–≤–∞—é—â–µ–º –º–µ—Ç–æ–¥–µ
        logger.info("üìä –ò—Å–ø–æ–ª—å–∑—É–µ–º –ø–µ—Ä–µ–¥–∞–Ω–Ω—ã–π OCR —Ä–µ–∑—É–ª—å—Ç–∞—Ç")
        
        # –î–û–ü–û–õ–ù–ò–¢–ï–õ–¨–ù–ê–Ø –ø—Ä–æ–≤–µ—Ä–∫–∞ –Ω–∞ –æ—Ç—Å—É—Ç—Å—Ç–≤–∏–µ —Ç–µ–∫—Å—Ç–∞
        text_content = ocr_result.get('text_content', '').strip()
        if not text_content or len(text_content) < 2:
            logger.warning("‚ö†Ô∏è OCR –≤–µ—Ä–Ω—É–ª –ø—É—Å—Ç–æ–π –∏–ª–∏ —Å–ª–∏—à–∫–æ–º –∫–æ—Ä–æ—Ç–∫–∏–π —Ç–µ–∫—Å—Ç")
            raise ValueError("–ù–∞ –∏–∑–æ–±—Ä–∞–∂–µ–Ω–∏–∏ –Ω–µ –æ–±–Ω–∞—Ä—É–∂–µ–Ω —á–∏—Ç–∞–µ–º—ã–π —Ç–µ–∫—Å—Ç –¥–ª—è –∞–Ω–∞–ª–∏–∑–∞")
        
        # –ü—Ä–æ–≤–µ—Ä—è–µ–º –∫–∞—á–µ—Å—Ç–≤–æ —Ä–∞—Å–ø–æ–∑–Ω–∞–≤–∞–Ω–∏—è
        confidence = ocr_result.get('confidence', 0.0)
        if confidence < 0.3:  # –ù–∏–∑–∫–∞—è —É–≤–µ—Ä–µ–Ω–Ω–æ—Å—Ç—å
            logger.warning(f"‚ö†Ô∏è –ù–∏–∑–∫–∞—è —É–≤–µ—Ä–µ–Ω–Ω–æ—Å—Ç—å OCR: {confidence:.2f}")
            raise ValueError("OCR –Ω–µ —Å–º–æ–≥ —É–≤–µ—Ä–µ–Ω–Ω–æ —Ä–∞—Å–ø–æ–∑–Ω–∞—Ç—å —Ç–µ–∫—Å—Ç –Ω–∞ –∏–∑–æ–±—Ä–∞–∂–µ–Ω–∏–∏")
        
        # –ü–æ–ª—É—á–∞–µ–º OCR —Ö–∞—Ä–∞–∫—Ç–µ—Ä–∏—Å—Ç–∏–∫–∏
        ocr_chars = self._get_ocr_based_characteristics(ocr_result)
        
        # –ö–æ–Ω–≤–µ—Ä—Ç–∏—Ä—É–µ–º –≤ FontCharacteristics –Ω–∞ –æ—Å–Ω–æ–≤–µ OCR –¥–∞–Ω–Ω—ã—Ö
        text_content = ocr_result.get('text_content', '').strip()
        
        # –ê–Ω–∞–ª–∏–∑–∏—Ä—É–µ–º —Ç–∏–ø —à—Ä–∏—Ñ—Ç–∞ –ø–æ —Å–æ–¥–µ—Ä–∂–∏–º–æ–º—É –∏ —Ä–∞–∑–º–µ—Ä–∞–º
        has_serifs = self._predict_serifs_from_ocr(ocr_chars, text_content)
        
        # –†–ï–ê–õ–¨–ù–´–ï —Ö–∞—Ä–∞–∫—Ç–µ—Ä–∏—Å—Ç–∏–∫–∏ –Ω–∞ –æ—Å–Ω–æ–≤–µ —Å–æ–¥–µ—Ä–∂–∏–º–æ–≥–æ –∏–∑–æ–±—Ä–∞–∂–µ–Ω–∏—è
        # stroke_width –Ω–∞ –æ—Å–Ω–æ–≤–µ —Ä–µ–∞–ª—å–Ω–æ–π —Ç–æ–ª—â–∏–Ω—ã —Ç–µ–∫—Å—Ç–∞
        if ocr_chars['avg_height'] > 0:
            # –ù–æ—Ä–º–∞–ª–∏–∑—É–µ–º —Ç–æ–ª—â–∏–Ω—É –æ—Ç–Ω–æ—Å–∏—Ç–µ–ª—å–Ω–æ —Ä–∞–∑–º–µ—Ä–∞ —Ç–µ–∫—Å—Ç–∞
            stroke_width = min(1.0, max(0.0, ocr_chars['avg_height'] / 50.0))
        else:
            stroke_width = 0.5
        
        # contrast –Ω–∞ –æ—Å–Ω–æ–≤–µ —Ä–µ–∞–ª—å–Ω–æ–π –≤–∞—Ä–∏–∞—Ç–∏–≤–Ω–æ—Å—Ç–∏ —Ä–∞–∑–º–µ—Ä–æ–≤
        if ocr_chars['height_variance'] > 0 and ocr_chars['avg_height'] > 0:
            # –ù–æ—Ä–º–∞–ª–∏–∑—É–µ–º –∫–æ–Ω—Ç—Ä–∞—Å—Ç
            contrast = min(1.0, max(0.0, ocr_chars['height_variance'] / ocr_chars['avg_height']))
        else:
            contrast = 0.3
        
        # –ù–∞–∫–ª–æ–Ω –Ω–∞ –æ—Å–Ω–æ–≤–µ —Ä–µ–∞–ª—å–Ω–æ–≥–æ —Å–æ–¥–µ—Ä–∂–∏–º–æ–≥–æ
        # –ê–Ω–∞–ª–∏–∑–∏—Ä—É–µ–º —Ç–µ–∫—Å—Ç –Ω–∞ –ø—Ä–µ–¥–º–µ—Ç –Ω–∞–∫–ª–æ–Ω–∞
        slant = 0.0  # –ü–æ–∫–∞ –±–µ–∑ –∞–Ω–∞–ª–∏–∑–∞ –Ω–∞–∫–ª–æ–Ω–∞
        
        # –£–Ω–∏–∫–∞–ª—å–Ω–æ—Å—Ç—å —á–µ—Ä–µ–∑ —Ä–µ–∞–ª—å–Ω–æ–µ —Å–æ–¥–µ—Ä–∂–∏–º–æ–µ –∏–∑–æ–±—Ä–∞–∂–µ–Ω–∏—è
        content_hash = hash(text_content + str(ocr_chars['regions_count']) + str(ocr_chars['avg_height']))
        unique_factor = (content_hash % 1000) / 1000.0
        
        # –î–ï–¢–ê–õ–¨–ù–û–ï –õ–û–ì–ò–†–û–í–ê–ù–ò–ï –¥–ª—è –æ—Ç–ª–∞–¥–∫–∏
        logger.info(f"üîç –£–ù–ò–ö–ê–õ–¨–ù–´–ï –•–ê–†–ê–ö–¢–ï–†–ò–°–¢–ò–ö–ò –ò–ó–û–ë–†–ê–ñ–ï–ù–ò–Ø:")
        logger.info(f"  - –¢–µ–∫—Å—Ç: '{text_content[:50]}...' (–¥–ª–∏–Ω–∞: {len(text_content)})")
        logger.info(f"  - –†–µ–≥–∏–æ–Ω—ã: {ocr_chars['regions_count']}")
        logger.info(f"  - –°—Ä–µ–¥–Ω—è—è –≤—ã—Å–æ—Ç–∞: {ocr_chars['avg_height']:.2f}")
        logger.info(f"  - –•–µ—à —Å–æ–¥–µ—Ä–∂–∏–º–æ–≥–æ: {content_hash}")
        logger.info(f"  - –£–Ω–∏–∫–∞–ª—å–Ω—ã–π —Ñ–∞–∫—Ç–æ—Ä: {unique_factor:.3f}")
        logger.info(f"  - stroke_width: {stroke_width:.3f}")
        logger.info(f"  - contrast: {contrast:.3f}")
        logger.info(f"  - slant: {slant:.3f}")
        
        # –ì–µ–æ–º–µ—Ç—Ä–∏—á–µ—Å–∫–∏–µ —Ö–∞—Ä–∞–∫—Ç–µ—Ä–∏—Å—Ç–∏–∫–∏ –∏–∑ OCR
        avg_height = ocr_chars['avg_height']
        x_height = avg_height * 0.6  # –ü—Ä–∏–º–µ—Ä–Ω–∞—è –ø—Ä–æ–ø–æ—Ä—Ü–∏—è
        cap_height = avg_height
        ascender = avg_height * 1.2
        descender = avg_height * 0.3
        
        # –ò–Ω—Ç–µ—Ä–≤–∞–ª—ã –Ω–∞ –æ—Å–Ω–æ–≤–µ –ø–ª–æ—Ç–Ω–æ—Å—Ç–∏ —Ç–µ–∫—Å—Ç–∞
        letter_spacing = ocr_chars['avg_width'] / max(ocr_chars['avg_word_length'], 1) * 0.1
        word_spacing = ocr_chars['avg_width'] * 0.3
        density = ocr_chars['text_density']
        
        # –ö–∏—Ä–∏–ª–ª–∏—á–µ—Å–∫–∏–µ –æ—Å–æ–±–µ–Ω–Ω–æ—Å—Ç–∏
        cyrillic_features = {
            'has_cyrillic': ocr_chars['has_cyrillic'],
            'cyrillic_ratio': 1.0 if ocr_chars['has_cyrillic'] else 0.0,
            'specific_letters': []
        }
        
        logger.info(f"OCR —Ö–∞—Ä–∞–∫—Ç–µ—Ä–∏—Å—Ç–∏–∫–∏ —à—Ä–∏—Ñ—Ç–∞: –∑–∞—Å–µ—á–∫–∏={has_serifs}, —Ç–æ–ª—â–∏–Ω–∞={stroke_width:.1f}, –≤—ã—Å–æ—Ç–∞={avg_height:.1f}")
        
        return FontCharacteristics(
            has_serifs=has_serifs,
            stroke_width=stroke_width,
            contrast=contrast,
            slant=slant,
            cyrillic_features=cyrillic_features,
            x_height=x_height,
            cap_height=cap_height,
            ascender=ascender,
            descender=descender,
            letter_spacing=letter_spacing,
            word_spacing=word_spacing,
            density=density
        )
    
    def _predict_serifs_from_ocr(self, ocr_chars: dict, text_content: str) -> bool:
        """–ü—Ä–µ–¥—Å–∫–∞–∑–∞–Ω–∏–µ –Ω–∞–ª–∏—á–∏—è –∑–∞—Å–µ—á–µ–∫ –Ω–∞ –æ—Å–Ω–æ–≤–µ OCR –¥–∞–Ω–Ω—ã—Ö"""
        # –≠–≤—Ä–∏—Å—Ç–∏–∫–∞: –µ—Å–ª–∏ —Ç–µ–∫—Å—Ç —Ñ–æ—Ä–º–∞–ª—å–Ω—ã–π –∏ —Ä–∞–∑–º–µ—Ä—ã —Å—Ç–∞–±–∏–ª—å–Ω—ã–µ - –≤–æ–∑–º–æ–∂–Ω–æ –∑–∞—Å–µ—á–∫–∏
        has_formal_text = any(word.lower() in ['–æ—Ñ–∏—Ü–∏–∞–ª—å–Ω—ã–π', '–¥–æ–∫—É–º–µ–Ω—Ç', '–∫–Ω–∏–≥–∞', '—Å—Ç–∞—Ç—å—è'] for word in text_content.split())
        stable_sizes = ocr_chars['height_variance'] < ocr_chars['avg_height'] * 0.2
        
        return has_formal_text and stable_sizes
    
    def _detect_serifs(self, binary: np.ndarray) -> bool:
        """–û–ø—Ä–µ–¥–µ–ª–µ–Ω–∏–µ –Ω–∞–ª–∏—á–∏—è –∑–∞—Å–µ—á–µ–∫"""
        # –ü—Ä–∏–º–µ–Ω—è–µ–º –º–æ—Ä—Ñ–æ–ª–æ–≥–∏—á–µ—Å–∫–∏–µ –æ–ø–µ—Ä–∞—Ü–∏–∏ –¥–ª—è –≤—ã–¥–µ–ª–µ–Ω–∏—è –º–µ–ª–∫–∏—Ö –¥–µ—Ç–∞–ª–µ–π
        kernel = cv2.getStructuringElement(cv2.MORPH_RECT, (3, 3))
        opened = cv2.morphologyEx(binary, cv2.MORPH_OPEN, kernel)
        
        # –ù–∞—Ö–æ–¥–∏–º —Ä–∞–∑–Ω–æ—Å—Ç—å - –º–µ–ª–∫–∏–µ –¥–µ—Ç–∞–ª–∏ (–ø–æ—Ç–µ–Ω—Ü–∏–∞–ª—å–Ω—ã–µ –∑–∞—Å–µ—á–∫–∏)
        diff = cv2.absdiff(binary, opened)
        serif_pixels = np.sum(diff == 255)
        total_text_pixels = np.sum(binary == 0)  # –ß–µ—Ä–Ω—ã–µ –ø–∏–∫—Å–µ–ª–∏ –≤ –±–∏–Ω–∞—Ä–Ω–æ–º –∏–∑–æ–±—Ä–∞–∂–µ–Ω–∏–∏
        
        if total_text_pixels == 0:
            return False
        
        serif_ratio = serif_pixels / total_text_pixels
        has_serifs = serif_ratio > 0.05  # –≠–º–ø–∏—Ä–∏—á–µ—Å–∫–∏–π –ø–æ—Ä–æ–≥
        
        logger.info(f"–ê–Ω–∞–ª–∏–∑ –∑–∞—Å–µ—á–µ–∫: —Å–æ–æ—Ç–Ω–æ—à–µ–Ω–∏–µ={serif_ratio:.3f}, —Ä–µ–∑—É–ª—å—Ç–∞—Ç={has_serifs}")
        return has_serifs
    
    def _analyze_stroke_width(self, binary: np.ndarray) -> float:
        """–ê–Ω–∞–ª–∏–∑ —Ç–æ–ª—â–∏–Ω—ã —à—Ç—Ä–∏—Ö–æ–≤"""
        # –ò—Å–ø–æ–ª—å–∑—É–µ–º —Ä–∞—Å—Å—Ç–æ—è–Ω–∏–µ –¥–æ –±–ª–∏–∂–∞–π—à–µ–≥–æ –Ω—É–ª—è (distance transform)
        dist_transform = cv2.distanceTransform(255 - binary, cv2.DIST_L2, 5)
        
        # –ù–∞—Ö–æ–¥–∏–º —Å—Ä–µ–¥–Ω—é—é —Ç–æ–ª—â–∏–Ω—É —à—Ç—Ä–∏—Ö–æ–≤
        text_pixels = binary == 0
        if np.sum(text_pixels) == 0:
            return 0.1
        
        avg_thickness = np.mean(dist_transform[text_pixels]) * 2  # –£–º–Ω–æ–∂–∞–µ–º –Ω–∞ 2 –¥–ª—è –ø–æ–ª–Ω–æ–π —à–∏—Ä–∏–Ω—ã
        
        # –ù–æ—Ä–º–∞–ª–∏–∑—É–µ–º –æ—Ç–Ω–æ—Å–∏—Ç–µ–ª—å–Ω–æ —Ä–∞–∑–º–µ—Ä–∞ –∏–∑–æ–±—Ä–∞–∂–µ–Ω–∏—è
        normalized_thickness = avg_thickness / max(binary.shape)
        
        # –î–æ–ø–æ–ª–Ω–∏—Ç–µ–ª—å–Ω–∞—è –Ω–æ—Ä–º–∞–ª–∏–∑–∞—Ü–∏—è –¥–ª—è –≥–∞—Ä–∞–Ω—Ç–∏–∏ –¥–∏–∞–ø–∞–∑–æ–Ω–∞ [0, 1]
        normalized_thickness = normalized_thickness / 10.0  # –î–µ–ª–∏–º –Ω–∞ 10 –¥–ª—è –±–æ–ª–µ–µ —Ä–µ–∞–ª–∏—Å—Ç–∏—á–Ω—ã—Ö –∑–Ω–∞—á–µ–Ω–∏–π
        
        return min(1.0, max(0.0, normalized_thickness))
    
    def _analyze_contrast(self, gray: np.ndarray) -> float:
        """–ê–Ω–∞–ª–∏–∑ –∫–æ–Ω—Ç—Ä–∞—Å—Ç–∞"""
        # –í—ã—á–∏—Å–ª—è–µ–º —Å—Ç–∞–Ω–¥–∞—Ä—Ç–Ω–æ–µ –æ—Ç–∫–ª–æ–Ω–µ–Ω–∏–µ –∫–∞–∫ –º–µ—Ä—É –∫–æ–Ω—Ç—Ä–∞—Å—Ç–∞
        std_dev = np.std(gray)
        
        # –ù–æ—Ä–º–∞–ª–∏–∑—É–µ–º –∫ –¥–∏–∞–ø–∞–∑–æ–Ω—É 0-1
        contrast = std_dev / 128.0
        
        return min(1.0, max(0.0, contrast))
    
    def _analyze_slant(self, binary: np.ndarray) -> float:
        """–ê–Ω–∞–ª–∏–∑ –Ω–∞–∫–ª–æ–Ω–∞ —Ç–µ–∫—Å—Ç–∞"""
        # –ò—Å–ø–æ–ª—å–∑—É–µ–º –ø—Ä–µ–æ–±—Ä–∞–∑–æ–≤–∞–Ω–∏–µ –•–∞—Ñ–∞ –¥–ª—è –ø–æ–∏—Å–∫–∞ –¥–æ–º–∏–Ω–∏—Ä—É—é—â–∏—Ö –ª–∏–Ω–∏–π
        edges = cv2.Canny(binary, 50, 150)
        lines = cv2.HoughLines(edges, 1, np.pi/180, threshold=50)
        
        if lines is None:
            return 0.0
        
        angles = []
        for line in lines[:20]:  # –ë–µ—Ä–µ–º –ø–µ—Ä–≤—ã–µ 20 –ª–∏–Ω–∏–π
            rho, theta = line[0]
            angle = theta * 180 / np.pi
            
            # –ò–Ω—Ç–µ—Ä–µ—Å—É—é—Ç –≤–µ—Ä—Ç–∏–∫–∞–ª—å–Ω—ã–µ –ª–∏–Ω–∏–∏ (–æ–∫–æ–ª–æ 90 –≥—Ä–∞–¥—É—Å–æ–≤)
            if 80 <= angle <= 100:
                angles.append(angle - 90)
        
        if not angles:
            return 0.0
        
        # –í–æ–∑–≤—Ä–∞—â–∞–µ–º —Å—Ä–µ–¥–Ω–∏–π –Ω–∞–∫–ª–æ–Ω
        return np.mean(angles)
    
    def _analyze_geometry(self, binary: np.ndarray) -> Tuple[float, float, float, float]:
        """–ê–Ω–∞–ª–∏–∑ –≥–µ–æ–º–µ—Ç—Ä–∏—á–µ—Å–∫–∏—Ö —Ö–∞—Ä–∞–∫—Ç–µ—Ä–∏—Å—Ç–∏–∫"""
        # –ù–∞—Ö–æ–¥–∏–º –∫–æ–Ω—Ç—É—Ä—ã –±—É–∫–≤
        contours, _ = cv2.findContours(binary, cv2.RETR_EXTERNAL, cv2.CHAIN_APPROX_SIMPLE)
        
        if not contours:
            return 50.0, 70.0, 80.0, 20.0
        
        # –ê–Ω–∞–ª–∏–∑–∏—Ä—É–µ–º –≤—ã—Å–æ—Ç—ã –±—É–∫–≤
        heights = []
        for contour in contours:
            _, _, _, h = cv2.boundingRect(contour)
            if h > 10:  # –§–∏–ª—å—Ç—Ä—É–µ–º —Å–ª–∏—à–∫–æ–º –º–∞–ª–µ–Ω—å–∫–∏–µ –∫–æ–Ω—Ç—É—Ä—ã
                heights.append(h)
        
        if not heights:
            return 50.0, 70.0, 80.0, 20.0
        
        # –≠–º–ø–∏—Ä–∏—á–µ—Å–∫–∏–µ —Å–æ–æ—Ç–Ω–æ—à–µ–Ω–∏—è –¥–ª—è –∫–∏—Ä–∏–ª–ª–∏—á–µ—Å–∫–∏—Ö —à—Ä–∏—Ñ—Ç–æ–≤
        avg_height = np.mean(heights)
        x_height = avg_height * 0.5
        cap_height = avg_height * 0.7
        ascender = avg_height * 0.8
        descender = avg_height * 0.2
        
        return x_height, cap_height, ascender, descender
    
    def _analyze_spacing(self, binary: np.ndarray) -> Tuple[float, float]:
        """–ê–Ω–∞–ª–∏–∑ –º–µ–∂–±—É–∫–≤–µ–Ω–Ω—ã—Ö –∏ –º–µ–∂—Å–ª–æ–≤–Ω—ã—Ö —Ä–∞—Å—Å—Ç–æ—è–Ω–∏–π"""
        # –£–ø—Ä–æ—â–µ–Ω–Ω—ã–π –∞–Ω–∞–ª–∏–∑ - –≤ —Ä–µ–∞–ª—å–Ω–æ—Å—Ç–∏ –Ω—É–∂–µ–Ω –±–æ–ª–µ–µ —Å–ª–æ–∂–Ω—ã–π –∞–ª–≥–æ—Ä–∏—Ç–º
        height, width = binary.shape
        
        # –ê–Ω–∞–ª–∏–∑–∏—Ä—É–µ–º –≥–æ—Ä–∏–∑–æ–Ω—Ç–∞–ª—å–Ω—ã–µ –ø—Ä–æ–µ–∫—Ü–∏–∏ –¥–ª—è –æ–ø—Ä–µ–¥–µ–ª–µ–Ω–∏—è —Ä–∞—Å—Å—Ç–æ—è–Ω–∏–π
        horizontal_projection = np.sum(binary == 0, axis=0)
        
        # –ù–∞—Ö–æ–¥–∏–º –ø—Ä–æ–º–µ–∂—É—Ç–∫–∏ –º–µ–∂–¥—É –±—É–∫–≤–∞–º–∏
        gaps = []
        in_gap = False
        gap_start = 0
        
        for i, projection in enumerate(horizontal_projection):
            if projection == 0 and not in_gap:  # –ù–∞—á–∞–ª–æ –ø—Ä–æ–º–µ–∂—É—Ç–∫–∞
                in_gap = True
                gap_start = i
            elif projection > 0 and in_gap:  # –ö–æ–Ω–µ—Ü –ø—Ä–æ–º–µ–∂—É—Ç–∫–∞
                gaps.append(i - gap_start)
                in_gap = False
        
        if gaps:
            letter_spacing = np.mean(gaps)
            word_spacing = np.percentile(gaps, 75) if len(gaps) > 1 else letter_spacing * 2
        else:
            letter_spacing = 2.0
            word_spacing = 6.0
        
        return letter_spacing, word_spacing
    
    def _calculate_density(self, binary: np.ndarray) -> float:
        """–†–∞—Å—á–µ—Ç –ø–ª–æ—Ç–Ω–æ—Å—Ç–∏ —Ç–µ–∫—Å—Ç–∞"""
        text_pixels = np.sum(binary == 0)
        total_pixels = binary.shape[0] * binary.shape[1]
        
        return text_pixels / total_pixels if total_pixels > 0 else 0.0
    
    def _analyze_cyrillic_features(self, binary: np.ndarray) -> CyrillicFeatures:
        """
        –ê–Ω–∞–ª–∏–∑ –æ—Å–æ–±–µ–Ω–Ω–æ—Å—Ç–µ–π –∫–∏—Ä–∏–ª–ª–∏—á–µ—Å–∫–∏—Ö –±—É–∫–≤
        –£–ø—Ä–æ—â–µ–Ω–Ω–∞—è –≤–µ—Ä—Å–∏—è - –≤ —Ä–µ–∞–ª—å–Ω–æ—Å—Ç–∏ –Ω—É–∂–Ω–æ —Ä–∞—Å–ø–æ–∑–Ω–∞–≤–∞–Ω–∏–µ –∫–æ–Ω–∫—Ä–µ—Ç–Ω—ã—Ö –±—É–∫–≤
        """
        # –ü–æ–∫–∞ –≤–æ–∑–≤—Ä–∞—â–∞–µ–º —Å–ª—É—á–∞–π–Ω—ã–µ –∑–Ω–∞—á–µ–Ω–∏—è –Ω–∞ –æ—Å–Ω–æ–≤–µ –æ–±—â–∏—Ö —Ö–∞—Ä–∞–∫—Ç–µ—Ä–∏—Å—Ç–∏–∫ –∏–∑–æ–±—Ä–∞–∂–µ–Ω–∏—è
        height, width = binary.shape
        text_density = self._calculate_density(binary)
        
        # –ì–µ–Ω–µ—Ä–∏—Ä—É–µ–º —Ö–∞—Ä–∞–∫—Ç–µ—Ä–∏—Å—Ç–∏–∫–∏ –Ω–∞ –æ—Å–Ω–æ–≤–µ —Å–≤–æ–π—Å—Ç–≤ –∏–∑–æ–±—Ä–∞–∂–µ–Ω–∏—è
        base_value = (height * width) % 100 / 100
        
        return CyrillicFeatures(
            ya_shape=0.5 + (text_density * base_value) % 0.4,
            zh_shape=0.6 + (width % 50) / 125,
            fi_shape=0.7 + (height % 30) / 100,
            shcha_shape=0.8 + (text_density * 100) % 20 / 100,
            yery_shape=0.5 + ((width + height) % 50) / 100
        )
    
    def _segment_image(self, gray: np.ndarray) -> list:
        """–†–∞–∑–±–∏–≤–∫–∞ –∏–∑–æ–±—Ä–∞–∂–µ–Ω–∏—è –Ω–∞ —Å–µ–≥–º–µ–Ω—Ç—ã –¥–ª—è —É–ª—É—á—à–µ–Ω–Ω–æ–≥–æ –∞–Ω–∞–ª–∏–∑–∞"""
        try:
            height, width = gray.shape
            segments = []
            
            # –ü–æ–¥—Ö–æ–¥ 1: –†–∞–∑–±–∏–≤–∫–∞ –Ω–∞ —Å–µ—Ç–∫—É (–∞–¥–∞–ø—Ç–∏–≤–Ω–∞—è)
            if height > 300 and width > 300:
                # –î–ª—è –±–æ–ª—å—à–∏—Ö –∏–∑–æ–±—Ä–∞–∂–µ–Ω–∏–π - —Å–µ—Ç–∫–∞ 4x4
                rows, cols = 4, 4
            elif height > 150 and width > 150:
                # –î–ª—è —Å—Ä–µ–¥–Ω–∏—Ö –∏–∑–æ–±—Ä–∞–∂–µ–Ω–∏–π - —Å–µ—Ç–∫–∞ 3x3
                rows, cols = 3, 3
            else:
                # –î–ª—è –º–∞–ª–µ–Ω—å–∫–∏—Ö - —Å–µ—Ç–∫–∞ 2x2
                rows, cols = 2, 2
            
            segment_height = height // rows
            segment_width = width // cols
            
            for i in range(rows):
                for j in range(cols):
                    y1 = i * segment_height
                    y2 = min((i + 1) * segment_height, height)
                    x1 = j * segment_width
                    x2 = min((j + 1) * segment_width, width)
                    
                    segment = gray[y1:y2, x1:x2]
                    if segment.size > 1000:  # –ú–∏–Ω–∏–º–∞–ª—å–Ω—ã–π —Ä–∞–∑–º–µ—Ä —Å–µ–≥–º–µ–Ω—Ç–∞
                        segments.append({
                            'image': segment,
                            'position': (x1, y1, x2, y2),
                            'type': 'grid'
                        })
            
            # –ü–æ–¥—Ö–æ–¥ 2: –¶–µ–Ω—Ç—Ä–∞–ª—å–Ω–∞—è –æ–±–ª–∞—Å—Ç—å (—á–∞—Å—Ç–æ —Å–æ–¥–µ—Ä–∂–∏—Ç –æ—Å–Ω–æ–≤–Ω–æ–π —Ç–µ–∫—Å—Ç)
            center_margin = min(height, width) // 6
            if center_margin > 0:
                center_y1 = center_margin
                center_y2 = height - center_margin
                center_x1 = center_margin
                center_x2 = width - center_margin
                
                if center_y2 > center_y1 and center_x2 > center_x1:
                    center_segment = gray[center_y1:center_y2, center_x1:center_x2]
                    if center_segment.size > 2000:
                        segments.append({
                            'image': center_segment,
                            'position': (center_x1, center_y1, center_x2, center_y2),
                            'type': 'center'
                        })
            
            # –ü–æ–¥—Ö–æ–¥ 3: –ì–æ—Ä–∏–∑–æ–Ω—Ç–∞–ª—å–Ω—ã–µ –ø–æ–ª–æ—Å—ã (–¥–ª—è –∑–∞–≥–æ–ª–æ–≤–∫–æ–≤)
            strip_height = height // 3
            for i in range(3):
                y1 = i * strip_height
                y2 = min((i + 1) * strip_height, height)
                
                strip_segment = gray[y1:y2, :]
                if strip_segment.size > 2000:
                    segments.append({
                        'image': strip_segment,
                        'position': (0, y1, width, y2),
                        'type': 'horizontal_strip'
                    })
            
            logger.info(f"–°–æ–∑–¥–∞–Ω–æ {len(segments)} —Å–µ–≥–º–µ–Ω—Ç–æ–≤ –¥–ª—è –∞–Ω–∞–ª–∏–∑–∞")
            return segments
            
        except Exception as e:
            logger.error(f"–û—à–∏–±–∫–∞ —Å–µ–≥–º–µ–Ω—Ç–∞—Ü–∏–∏: {str(e)}")
            return [{'image': gray, 'position': (0, 0, gray.shape[1], gray.shape[0]), 'type': 'full'}]
    
    def _analyze_segment_for_text(self, segment_data: dict) -> bool:
        """–£–ª—É—á—à–µ–Ω–Ω—ã–π –∞–Ω–∞–ª–∏–∑ —Å–µ–≥–º–µ–Ω—Ç–∞ –Ω–∞ –Ω–∞–ª–∏—á–∏–µ —Ç–µ–∫—Å—Ç–∞"""
        try:
            segment = segment_data['image']
            position = segment_data['position']
            segment_type = segment_data['type']
            
            # –ü—Ä–æ–ø—É—Å–∫–∞–µ–º —Å–ª–∏—à–∫–æ–º –º–∞–ª–µ–Ω—å–∫–∏–µ —Å–µ–≥–º–µ–Ω—Ç—ã
            if segment.shape[0] < 30 or segment.shape[1] < 30:
                return False
            
            # –ú–Ω–æ–∂–µ—Å—Ç–≤–µ–Ω–Ω–∞—è –±–∏–Ω–∞—Ä–∏–∑–∞—Ü–∏—è –¥–ª—è –ª—É—á—à–µ–≥–æ –≤—ã–¥–µ–ª–µ–Ω–∏—è —Ç–µ–∫—Å—Ç–∞
            results = []
            
            # –ú–µ—Ç–æ–¥ 1: –ê–¥–∞–ø—Ç–∏–≤–Ω–∞—è –±–∏–Ω–∞—Ä–∏–∑–∞—Ü–∏—è
            try:
                binary1 = cv2.adaptiveThreshold(segment, 255, cv2.ADAPTIVE_THRESH_GAUSSIAN_C, cv2.THRESH_BINARY, 11, 2)
                results.append(self._analyze_binary_for_text(binary1))
            except:
                pass
            
            # –ú–µ—Ç–æ–¥ 2: –ì–ª–æ–±–∞–ª—å–Ω–∞—è –±–∏–Ω–∞—Ä–∏–∑–∞—Ü–∏—è —Å Otsu
            try:
                _, binary2 = cv2.threshold(segment, 0, 255, cv2.THRESH_BINARY + cv2.THRESH_OTSU)
                results.append(self._analyze_binary_for_text(binary2))
            except:
                pass
            
            # –ú–µ—Ç–æ–¥ 3: –ë–∏–Ω–∞—Ä–∏–∑–∞—Ü–∏—è –ø–æ —Å—Ä–µ–¥–Ω–µ–º—É –∑–Ω–∞—á–µ–Ω–∏—é
            try:
                mean_val = np.mean(segment)
                binary3 = (segment < mean_val * 0.8).astype(np.uint8) * 255
                results.append(self._analyze_binary_for_text(binary3))
            except:
                pass
            
            # –ú–µ—Ç–æ–¥ 4: –ò–ù–í–ï–†–¢–ò–†–û–í–ê–ù–ù–ê–Ø –±–∏–Ω–∞—Ä–∏–∑–∞—Ü–∏—è (–¥–ª—è —Å–≤–µ—Ç–ª–æ–≥–æ —Ç–µ–∫—Å—Ç–∞ –Ω–∞ —Å–≤–µ—Ç–ª–æ–º —Ñ–æ–Ω–µ)
            try:
                # –ò—â–µ–º —Å–≤–µ—Ç–ª—ã–µ –æ–±–ª–∞—Å—Ç–∏ –∫–∞–∫ —Ç–µ–∫—Å—Ç (–∏–Ω–≤–µ—Ä—Ç–∏—Ä—É–µ–º –ª–æ–≥–∏–∫—É)
                mean_val = np.mean(segment)
                binary4 = (segment > mean_val * 1.1).astype(np.uint8) * 255
                results.append(self._analyze_binary_for_text(binary4))
            except:
                pass
            
            # –ú–µ—Ç–æ–¥ 5: –î–µ—Ç–µ–∫—Ü–∏—è –≥—Ä–∞–Ω–∏—Ü —Å –ø–æ—Å–ª–µ–¥—É—é—â–µ–π –º–æ—Ä—Ñ–æ–ª–æ–≥–∏–µ–π
            try:
                # –ù–∞—Ö–æ–¥–∏–º –≥—Ä–∞–Ω–∏—Ü—ã
                edges = cv2.Canny(segment, 30, 100)
                # –†–∞—Å—à–∏—Ä—è–µ–º –≥—Ä–∞–Ω–∏—Ü—ã —á—Ç–æ–±—ã "—Å–æ–µ–¥–∏–Ω–∏—Ç—å" –±—É–∫–≤—ã
                kernel = cv2.getStructuringElement(cv2.MORPH_RECT, (3, 3))
                binary5 = cv2.dilate(edges, kernel, iterations=1)
                results.append(self._analyze_binary_for_text(binary5))
            except:
                pass
            
            # –ï—Å–ª–∏ —Ö–æ—Ç—è –±—ã –æ–¥–∏–Ω –º–µ—Ç–æ–¥ –Ω–∞—à–µ–ª —Ç–µ–∫—Å—Ç - —Å—á–∏—Ç–∞–µ–º —á—Ç–æ —Ç–µ–∫—Å—Ç –µ—Å—Ç—å
            has_text = any(results)
            
            # –î–û–ü–û–õ–ù–ò–¢–ï–õ–¨–ù–ê–Ø –ü–†–û–í–ï–†–ö–ê: –µ—Å–ª–∏ –≤—Å–µ –º–µ—Ç–æ–¥—ã –Ω–µ —Å—Ä–∞–±–æ—Ç–∞–ª–∏, –ø—Ä–æ–≤–µ—Ä—è–µ–º –ø—Ä–æ—Å—Ç–æ –∫–æ–Ω—Ç—Ä–∞—Å—Ç–Ω–æ—Å—Ç—å
            if not has_text:
                contrast = np.std(segment.astype(np.float64))
                # –ï—Å–ª–∏ –µ—Å—Ç—å —Ö–æ—Ä–æ—à–∏–π –∫–æ–Ω—Ç—Ä–∞—Å—Ç - –≤–æ–∑–º–æ–∂–Ω–æ —ç—Ç–æ —Å—Ç–∏–ª–∏–∑–æ–≤–∞–Ω–Ω—ã–π —Ç–µ–∫—Å—Ç
                if contrast > 15:  # –°–Ω–∏–∂–∞–µ–º –ø–æ—Ä–æ–≥ –¥–ª—è —Å–≤–µ—Ç–ª—ã—Ö –∏–∑–æ–±—Ä–∞–∂–µ–Ω–∏–π
                    has_text = True
                    logger.info(f"–¢–µ–∫—Å—Ç –Ω–∞–π–¥–µ–Ω –ø–æ –∫–æ–Ω—Ç—Ä–∞—Å—Ç–Ω–æ—Å—Ç–∏ –≤ —Å–µ–≥–º–µ–Ω—Ç–µ {segment_type}: contrast={contrast:.1f}")
                
                # –î–û–ü–û–õ–ù–ò–¢–ï–õ–¨–ù–ê–Ø –ü–†–û–í–ï–†–ö–ê 2: –∞–Ω–∞–ª–∏–∑ —Ç–µ–∫—Å—Ç—É—Ä—ã (–¥–ª—è –æ—á–µ–Ω—å —Å–≤–µ—Ç–ª—ã—Ö –∏–∑–æ–±—Ä–∞–∂–µ–Ω–∏–π)
                if not has_text:
                    # –ü—Ä–æ–≤–µ—Ä—è–µ–º –µ—Å—Ç—å –ª–∏ —Å—Ç—Ä—É–∫—Ç—É—Ä–∏—Ä–æ–≤–∞–Ω–Ω—ã–µ –æ–±–ª–∞—Å—Ç–∏
                    height, width = segment.shape
                    if height > 20 and width > 20:
                        # –ê–Ω–∞–ª–∏–∑–∏—Ä—É–µ–º –ª–æ–∫–∞–ª—å–Ω—ã–µ –≤–∞—Ä–∏–∞—Ü–∏–∏ –∏–Ω—Ç–µ–Ω—Å–∏–≤–Ω–æ—Å—Ç–∏
                        local_std_values = []
                        window_size = min(10, height//4, width//4)
                        
                        for y in range(0, height-window_size, window_size//2):
                            for x in range(0, width-window_size, window_size//2):
                                window = segment[y:y+window_size, x:x+window_size]
                                local_std = np.std(window.astype(np.float64))
                                local_std_values.append(local_std)
                        
                        if local_std_values:
                            max_local_std = max(local_std_values)
                            avg_local_std = np.mean(local_std_values)
                            
                            # –ï—Å–ª–∏ –µ—Å—Ç—å –æ–±–ª–∞—Å—Ç–∏ —Å –≤—ã—Å–æ–∫–æ–π –ª–æ–∫–∞–ª—å–Ω–æ–π –≤–∞—Ä–∏–∞—Ü–∏–µ–π - –≤–æ–∑–º–æ–∂–Ω–æ —Ç–µ–∫—Å—Ç
                            if max_local_std > 8 and avg_local_std > 3:
                                has_text = True
                                logger.info(f"–¢–µ–∫—Å—Ç –Ω–∞–π–¥–µ–Ω –ø–æ —Ç–µ–∫—Å—Ç—É—Ä–Ω–æ–º—É –∞–Ω–∞–ª–∏–∑—É –≤ —Å–µ–≥–º–µ–Ω—Ç–µ {segment_type}: max_std={max_local_std:.1f}, avg_std={avg_local_std:.1f}")
            
            if has_text:
                logger.info(f"–¢–µ–∫—Å—Ç –Ω–∞–π–¥–µ–Ω –≤ —Å–µ–≥–º–µ–Ω—Ç–µ {segment_type} –≤ –ø–æ–∑–∏—Ü–∏–∏ {position}")
            
            return has_text
            
        except Exception as e:
            logger.error(f"–û—à–∏–±–∫–∞ –∞–Ω–∞–ª–∏–∑–∞ —Å–µ–≥–º–µ–Ω—Ç–∞: {str(e)}")
            return False
    
    def _analyze_binary_for_text(self, binary: np.ndarray) -> bool:
        """–ê–Ω–∞–ª–∏–∑ –±–∏–Ω–∞—Ä–Ω–æ–≥–æ –∏–∑–æ–±—Ä–∞–∂–µ–Ω–∏—è –Ω–∞ –Ω–∞–ª–∏—á–∏–µ —Ç–µ–∫—Å—Ç–æ–≤—ã—Ö —Å—Ç—Ä—É–∫—Ç—É—Ä"""
        try:
            # –ü–æ–∏—Å–∫ –∫–æ–Ω—Ç—É—Ä–æ–≤
            contours, _ = cv2.findContours(binary, cv2.RETR_EXTERNAL, cv2.CHAIN_APPROX_SIMPLE)
            
            text_like_contours = 0
            total_text_area = 0
            
            for contour in contours:
                area = cv2.contourArea(contour)
                if 10 < area < 10000:  # –ï—â–µ –±–æ–ª–µ–µ —à–∏—Ä–æ–∫–∏–π –¥–∏–∞–ø–∞–∑–æ–Ω –¥–ª—è —Å–∏–º–≤–æ–ª–æ–≤
                    x, y, w, h = cv2.boundingRect(contour)
                    aspect_ratio = w / h if h > 0 else 0
                    
                    # –ü—Ä–æ–≤–µ—Ä—è–µ–º –ø—Ä–æ–ø–æ—Ä—Ü–∏–∏ —Å–∏–º–≤–æ–ª–∞ (–æ—á–µ–Ω—å –º—è–≥–∫–æ)
                    if 0.05 < aspect_ratio < 10.0:
                        # –î–æ–ø–æ–ª–Ω–∏—Ç–µ–ª—å–Ω—ã–µ –ø—Ä–æ–≤–µ—Ä–∫–∏ (—Å–º—è–≥—á–µ–Ω–Ω—ã–µ)
                        perimeter = cv2.arcLength(contour, True)
                        if perimeter > 0:
                            compactness = area / (perimeter * perimeter)
                            
                            # –°–∏–º–≤–æ–ª—ã –æ–±—ã—á–Ω–æ –Ω–µ —Å–ª–∏—à–∫–æ–º –∫–æ–º–ø–∞–∫—Ç–Ω—ã–µ (–æ—á–µ–Ω—å –º—è–≥–∫–∏–µ —Ç—Ä–µ–±–æ–≤–∞–Ω–∏—è)
                            if 0.005 < compactness < 0.5:
                                text_like_contours += 1
                                total_text_area += area
            
            # –ü—Ä–æ–≤–µ—Ä—è–µ–º –ø–ª–æ—Ç–Ω–æ—Å—Ç—å —Ç–µ–∫—Å—Ç–æ–≤—ã—Ö —ç–ª–µ–º–µ–Ω—Ç–æ–≤
            image_area = binary.shape[0] * binary.shape[1]
            text_density = total_text_area / image_area if image_area > 0 else 0
            
            # –ú–ê–ö–°–ò–ú–ê–õ–¨–ù–û –º—è–≥–∫–∏–µ —É—Å–ª–æ–≤–∏—è –¥–ª—è –æ–ø—Ä–µ–¥–µ–ª–µ–Ω–∏—è —Ç–µ–∫—Å—Ç–∞
            has_text = (
                text_like_contours >= 1 and  # –ú–∏–Ω–∏–º—É–º 1 —Å–∏–º–≤–æ–ª (–æ—á–µ–Ω—å –º—è–≥–∫–æ)
                0.0001 < text_density < 0.7  # –û—á–µ–Ω—å —à–∏—Ä–æ–∫–∏–π –¥–∏–∞–ø–∞–∑–æ–Ω –ø–ª–æ—Ç–Ω–æ—Å—Ç–∏
            )
            
            return has_text
            
        except Exception as e:
            logger.error(f"–û—à–∏–±–∫–∞ –∞–Ω–∞–ª–∏–∑–∞ –±–∏–Ω–∞—Ä–Ω–æ–≥–æ –∏–∑–æ–±—Ä–∞–∂–µ–Ω–∏—è: {str(e)}")
            return False
    
    def _final_complexity_check(self, gray: np.ndarray) -> bool:
        """–§–∏–Ω–∞–ª—å–Ω–∞—è –ø—Ä–æ–≤–µ—Ä–∫–∞ —Å–ª–æ–∂–Ω–æ—Å—Ç–∏ –∏–∑–æ–±—Ä–∞–∂–µ–Ω–∏—è - –¥–ª—è —Ä–µ–¥–∫–∏—Ö —Å–ª—É—á–∞–µ–≤"""
        try:
            logger.info("=== –§–ò–ù–ê–õ–¨–ù–ê–Ø –ü–†–û–í–ï–†–ö–ê –°–õ–û–ñ–ù–û–°–¢–ò ===")
            
            # –ü—Ä–æ–≤–µ—Ä–∫–∞ 1: –û–±—â–∞—è —ç–Ω—Ç—Ä–æ–ø–∏—è –∏–∑–æ–±—Ä–∞–∂–µ–Ω–∏—è (–∏–Ω—Ñ–æ—Ä–º–∞—Ü–∏–æ–Ω–Ω–∞—è —Å–ª–æ–∂–Ω–æ—Å—Ç—å)
            hist = cv2.calcHist([gray], [0], None, [256], [0, 256])
            hist = hist.flatten()
            hist = hist[hist > 0]  # –£–±–∏—Ä–∞–µ–º –Ω—É–ª–∏
            if len(hist) > 0:
                # –í—ã—á–∏—Å–ª—è–µ–º —ç–Ω—Ç—Ä–æ–ø–∏—é
                hist_norm = hist / np.sum(hist)
                entropy = -np.sum(hist_norm * np.log2(hist_norm + 1e-10))
                logger.info(f"–≠–Ω—Ç—Ä–æ–ø–∏—è –∏–∑–æ–±—Ä–∞–∂–µ–Ω–∏—è: {entropy:.2f}")
                
                # –í—ã—Å–æ–∫–∞—è —ç–Ω—Ç—Ä–æ–ø–∏—è —á–∞—Å—Ç–æ –æ–∑–Ω–∞—á–∞–µ—Ç —Å–ª–æ–∂–Ω–æ–µ –∏–∑–æ–±—Ä–∞–∂–µ–Ω–∏–µ —Å —Ç–µ–∫—Å—Ç–æ–º
                if entropy > 6.0:  # –í—ã—Å–æ–∫–∞—è –∏–Ω—Ñ–æ—Ä–º–∞—Ü–∏–æ–Ω–Ω–∞—è —Å–ª–æ–∂–Ω–æ—Å—Ç—å
                    logger.info("–í—ã—Å–æ–∫–∞—è —ç–Ω—Ç—Ä–æ–ø–∏—è - –≤–µ—Ä–æ—è—Ç–Ω–æ –µ—Å—Ç—å —Ç–µ–∫—Å—Ç")
                    return True
            
            # –ü—Ä–æ–≤–µ—Ä–∫–∞ 2: –ö–æ–ª–∏—á–µ—Å—Ç–≤–æ —É–Ω–∏–∫–∞–ª—å–Ω—ã—Ö –≥—Ä–∞–¥–∞—Ü–∏–π —Å–µ—Ä–æ–≥–æ
            unique_values = len(np.unique(gray))
            logger.info(f"–£–Ω–∏–∫–∞–ª—å–Ω—ã—Ö –≥—Ä–∞–¥–∞—Ü–∏–π: {unique_values}")
            
            # –ü—Ä–æ–≤–µ—Ä–∫–∞ 3: –õ–æ–∫–∞–ª—å–Ω–∞—è –≤–∞—Ä–∏–∞—Ü–∏—è (LBP - Local Binary Pattern –ø–æ–¥—Ö–æ–¥)
            height, width = gray.shape
            local_variations = 0
            
            # –ü—Ä–æ–≤–µ—Ä—è–µ–º –ª–æ–∫–∞–ª—å–Ω—ã–µ –≤–∞—Ä–∏–∞—Ü–∏–∏ –ø–æ —Å–µ—Ç–∫–µ
            step = max(10, min(height, width) // 20)
            for y in range(step, height - step, step):
                for x in range(step, width - step, step):
                    # –ë–µ—Ä–µ–º –æ–∫—Ä–µ—Å—Ç–Ω–æ—Å—Ç—å 3x3
                    neighborhood = gray[y-1:y+2, x-1:x+2]
                    if neighborhood.shape == (3, 3):
                        center = neighborhood[1, 1]
                        # –°—á–∏—Ç–∞–µ–º —Å–∫–æ–ª—å–∫–æ —Å–æ—Å–µ–¥–µ–π –æ—Ç–ª–∏—á–∞–µ—Ç—Å—è –æ—Ç —Ü–µ–Ω—Ç—Ä–∞
                        diff_count = np.sum(np.abs(neighborhood - center) > 10)
                        if diff_count >= 4:  # –ú–Ω–æ–≥–æ —Ä–∞–∑–ª–∏—á–∏–π - –≤–æ–∑–º–æ–∂–Ω–æ —Ç–µ–∫—Å—Ç
                            local_variations += 1
            
            variation_density = local_variations / ((height // step) * (width // step))
            logger.info(f"–ü–ª–æ—Ç–Ω–æ—Å—Ç—å –ª–æ–∫–∞–ª—å–Ω—ã—Ö –≤–∞—Ä–∏–∞—Ü–∏–π: {variation_density:.3f}")
            
            # –ü—Ä–æ–≤–µ—Ä–∫–∞ 4: –ì—Ä–∞–¥–∏–µ–Ω—Ç–Ω–∞—è –∞–∫—Ç–∏–≤–Ω–æ—Å—Ç—å
            grad_x = cv2.Sobel(gray, cv2.CV_64F, 1, 0, ksize=3)
            grad_y = cv2.Sobel(gray, cv2.CV_64F, 0, 1, ksize=3)
            gradient_magnitude = np.sqrt(grad_x**2 + grad_y**2)
            avg_gradient = np.mean(gradient_magnitude)
            logger.info(f"–°—Ä–µ–¥–Ω—è—è –≥—Ä–∞–¥–∏–µ–Ω—Ç–Ω–∞—è –∞–∫—Ç–∏–≤–Ω–æ—Å—Ç—å: {avg_gradient:.2f}")
            
            # –§–ò–ù–ê–õ–¨–ù–û–ï –†–ï–®–ï–ù–ò–ï: –µ—Å–ª–∏ –∏–∑–æ–±—Ä–∞–∂–µ–Ω–∏–µ —Å–ª–æ–∂–Ω–æ–µ –ø–æ –Ω–µ—Å–∫–æ–ª—å–∫–∏–º –∫—Ä–∏—Ç–µ—Ä–∏—è–º
            complexity_score = 0
            
            if entropy > 5.5:
                complexity_score += 1
                logger.info("+ –≠–Ω—Ç—Ä–æ–ø–∏—è —É–∫–∞–∑—ã–≤–∞–µ—Ç –Ω–∞ —Å–ª–æ–∂–Ω–æ—Å—Ç—å")
            
            if unique_values > 100:
                complexity_score += 1
                logger.info("+ –ú–Ω–æ–≥–æ –≥—Ä–∞–¥–∞—Ü–∏–π —Å–µ—Ä–æ–≥–æ")
            
            if variation_density > 0.3:
                complexity_score += 1
                logger.info("+ –í—ã—Å–æ–∫–∞—è –ª–æ–∫–∞–ª—å–Ω–∞—è –≤–∞—Ä–∏–∞—Ü–∏—è")
            
            if avg_gradient > 15:
                complexity_score += 1
                logger.info("+ –í—ã—Å–æ–∫–∞—è –≥—Ä–∞–¥–∏–µ–Ω—Ç–Ω–∞—è –∞–∫—Ç–∏–≤–Ω–æ—Å—Ç—å")
            
            # –ï—Å–ª–∏ –Ω–∞–±—Ä–∞–ª–∏ 2+ –±–∞–ª–ª–∞ –∏–∑ 4 - —Å—á–∏—Ç–∞–µ–º —á—Ç–æ –µ—Å—Ç—å —Ç–µ–∫—Å—Ç
            has_text = complexity_score >= 2
            
            # –≠–ö–°–¢–†–ï–ù–ù–ê–Ø –ú–ï–†–ê: –ø—Ä–æ–≤–µ—Ä–∫–∞ –Ω–∞ "—Ä–µ–∫–ª–∞–º–Ω—ã–π" —Ç–∏–ø –∏–∑–æ–±—Ä–∞–∂–µ–Ω–∏—è
            if not has_text:
                has_text = self._detect_advertisement_pattern(gray)
                if has_text:
                    logger.info("–û–±–Ω–∞—Ä—É–∂–µ–Ω —Ä–µ–∫–ª–∞–º–Ω—ã–π –ø–∞—Ç—Ç–µ—Ä–Ω - –ø—Ä–∏–Ω—É–¥–∏—Ç–µ–ª—å–Ω–æ —Å—á–∏—Ç–∞–µ–º —á—Ç–æ –µ—Å—Ç—å —Ç–µ–∫—Å—Ç")
            
            logger.info(f"–ò—Ç–æ–≥–æ–≤—ã–π —Å—á–µ—Ç —Å–ª–æ–∂–Ω–æ—Å—Ç–∏: {complexity_score}/4, —Ä–µ–∑—É–ª—å—Ç–∞—Ç: {has_text}")
            
            return has_text
            
        except Exception as e:
            logger.error(f"–û—à–∏–±–∫–∞ —Ñ–∏–Ω–∞–ª—å–Ω–æ–π –ø—Ä–æ–≤–µ—Ä–∫–∏: {str(e)}")
            return False  # –í —Å–ª—É—á–∞–µ –æ—à–∏–±–∫–∏ –Ω–µ –±–ª–æ–∫–∏—Ä—É–µ–º
    
    def _detect_advertisement_pattern(self, gray: np.ndarray) -> bool:
        """–û–ø—Ä–µ–¥–µ–ª–µ–Ω–∏–µ —Ä–µ–∫–ª–∞–º–Ω–æ–≥–æ/–±–∞–Ω–Ω–µ—Ä–Ω–æ–≥–æ –ø–∞—Ç—Ç–µ—Ä–Ω–∞ –∏–∑–æ–±—Ä–∞–∂–µ–Ω–∏—è"""
        try:
            logger.info("=== –ü–†–û–í–ï–†–ö–ê –†–ï–ö–õ–ê–ú–ù–û–ì–û –ü–ê–¢–¢–ï–†–ù–ê ===")
            
            height, width = gray.shape
            total_pixels = height * width
            
            logger.info(f"–†–∞–∑–º–µ—Ä –∏–∑–æ–±—Ä–∞–∂–µ–Ω–∏—è: {width}x{height} ({total_pixels} –ø–∏–∫—Å–µ–ª–µ–π)")
            
            # –ü—Ä–∏–∑–Ω–∞–∫ 1: –ü—Ä—è–º–æ—É–≥–æ–ª—å–Ω–∞—è —Ñ–æ—Ä–º–∞ (—Ç–∏–ø–∏—á–Ω–æ –¥–ª—è —Ä–µ–∫–ª–∞–º—ã)
            aspect_ratio = width / height if height > 0 else 0
            is_banner_shape = (
                (1.2 < aspect_ratio < 3.0) or  # –ì–æ—Ä–∏–∑–æ–Ω—Ç–∞–ª—å–Ω—ã–π –±–∞–Ω–Ω–µ—Ä
                (0.3 < aspect_ratio < 0.8)     # –í–µ—Ä—Ç–∏–∫–∞–ª—å–Ω—ã–π –±–∞–Ω–Ω–µ—Ä
            )
            
            # –ü—Ä–∏–∑–Ω–∞–∫ 2: –ü—Ä–µ–æ–±–ª–∞–¥–∞–Ω–∏–µ —Å–≤–µ—Ç–ª—ã—Ö —Ç–æ–Ω–æ–≤ (–±–µ–ª—ã–π/—Å–≤–µ—Ç–ª—ã–π —Ñ–æ–Ω)
            light_pixels = np.sum(gray > 200)  # –û—á–µ–Ω—å —Å–≤–µ—Ç–ª—ã–µ –ø–∏–∫—Å–µ–ª–∏
            light_ratio = light_pixels / total_pixels
            has_light_background = light_ratio > 0.4  # –ú–Ω–æ–≥–æ —Å–≤–µ—Ç–ª—ã—Ö –æ–±–ª–∞—Å—Ç–µ–π
            
            # –ü—Ä–∏–∑–Ω–∞–∫ 3: –ù–∞–ª–∏—á–∏–µ –∫–æ–Ω—Ç—Ä–∞—Å—Ç–Ω—ã—Ö –æ–±–ª–∞—Å—Ç–µ–π (—Ç–µ–∫—Å—Ç –Ω–∞ —Ñ–æ–Ω–µ)
            # –ò—â–µ–º –æ–±–ª–∞—Å—Ç–∏ —Å —Ä–µ–∑–∫–∏–º–∏ –ø–µ—Ä–µ—Ö–æ–¥–∞–º–∏
            edges = cv2.Canny(gray, 50, 150)
            edge_pixels = np.sum(edges > 0)
            edge_density = edge_pixels / total_pixels
            has_contrast_areas = edge_density > 0.02  # –ï—Å—Ç—å —á–µ—Ç–∫–∏–µ –≥—Ä–∞–Ω–∏—Ü—ã
            
            # –ü—Ä–∏–∑–Ω–∞–∫ 4: –°—Ç—Ä—É–∫—Ç—É—Ä–∏—Ä–æ–≤–∞–Ω–Ω–æ—Å—Ç—å (–Ω–µ —Ö–∞–æ—Ç–∏—á–Ω–æ–µ –∏–∑–æ–±—Ä–∞–∂–µ–Ω–∏–µ)
            # –ü—Ä–æ–≤–µ—Ä—è–µ–º –µ—Å—Ç—å –ª–∏ –≥–æ—Ä–∏–∑–æ–Ω—Ç–∞–ª—å–Ω—ã–µ/–≤–µ—Ä—Ç–∏–∫–∞–ª—å–Ω—ã–µ —Å—Ç—Ä—É–∫—Ç—É—Ä—ã
            horizontal_kernel = cv2.getStructuringElement(cv2.MORPH_RECT, (15, 1))
            vertical_kernel = cv2.getStructuringElement(cv2.MORPH_RECT, (1, 15))
            
            horizontal_lines = cv2.morphologyEx(edges, cv2.MORPH_CLOSE, horizontal_kernel)
            vertical_lines = cv2.morphologyEx(edges, cv2.MORPH_CLOSE, vertical_kernel)
            
            h_line_pixels = np.sum(horizontal_lines > 0)
            v_line_pixels = np.sum(vertical_lines > 0)
            
            has_structure = (h_line_pixels + v_line_pixels) > (total_pixels * 0.01)
            
            # –ü—Ä–∏–∑–Ω–∞–∫ 5: –†–∞–∑–º–µ—Ä –∏–∑–æ–±—Ä–∞–∂–µ–Ω–∏—è (—Ä–µ–∫–ª–∞–º–∞ –æ–±—ã—á–Ω–æ —Å—Ä–µ–¥–Ω–µ–≥–æ —Ä–∞–∑–º–µ—Ä–∞)
            reasonable_size = 10000 < total_pixels < 500000  # –û—Ç 100x100 –¥–æ 700x700 –ø—Ä–∏–º–µ—Ä–Ω–æ
            
            # –ü–æ–¥—Å—á–∏—Ç—ã–≤–∞–µ–º –±–∞–ª–ª—ã
            score = 0
            if is_banner_shape:
                score += 1
                logger.info("+ –§–æ—Ä–º–∞ –±–∞–Ω–Ω–µ—Ä–∞")
            
            if has_light_background:
                score += 1
                logger.info(f"+ –°–≤–µ—Ç–ª—ã–π —Ñ–æ–Ω ({light_ratio:.2%})")
            
            if has_contrast_areas:
                score += 1
                logger.info(f"+ –ö–æ–Ω—Ç—Ä–∞—Å—Ç–Ω—ã–µ –æ–±–ª–∞—Å—Ç–∏ ({edge_density:.3%})")
            
            if has_structure:
                score += 1
                logger.info("+ –°—Ç—Ä—É–∫—Ç—É—Ä–∏—Ä–æ–≤–∞–Ω–Ω–æ—Å—Ç—å")
            
            if reasonable_size:
                score += 1
                logger.info(f"+ –†–∞–∑—É–º–Ω—ã–π —Ä–∞–∑–º–µ—Ä ({total_pixels} –ø–∏–∫—Å–µ–ª–µ–π)")
            
            # –î–û–ü–û–õ–ù–ò–¢–ï–õ–¨–ù–ê–Ø –≠–í–†–ò–°–¢–ò–ö–ê: –µ—Å–ª–∏ —ç—Ç–æ —è–≤–Ω–æ —Ä–µ–∫–ª–∞–º–Ω–æ–µ –∏–∑–æ–±—Ä–∞–∂–µ–Ω–∏–µ
            # –∏ —Ä–∞–∑–º–µ—Ä —Ä–∞–∑—É–º–Ω—ã–π - –ø—Ä–∏–Ω—É–¥–∏—Ç–µ–ª—å–Ω–æ —Å—á–∏—Ç–∞–µ–º —á—Ç–æ –µ—Å—Ç—å —Ç–µ–∫—Å—Ç
            if score >= 1 and reasonable_size and has_light_background:
                logger.info("–≠–í–†–ò–°–¢–ò–ö–ê: –°–≤–µ—Ç–ª–æ–µ –∏–∑–æ–±—Ä–∞–∂–µ–Ω–∏–µ —Ä–∞–∑—É–º–Ω–æ–≥–æ —Ä–∞–∑–º–µ—Ä–∞ - –≤–µ—Ä–æ—è—Ç–Ω–æ —Ä–µ–∫–ª–∞–º–∞ —Å —Ç–µ–∫—Å—Ç–æ–º")
                is_advertisement = True
            else:
                # –ï—Å–ª–∏ –Ω–∞–±—Ä–∞–ª–∏ 2+ –±–∞–ª–ª–∞ –∏–∑ 5 - —Å–∫–æ—Ä–µ–µ –≤—Å–µ–≥–æ —Ä–µ–∫–ª–∞–º–∞ —Å —Ç–µ–∫—Å—Ç–æ–º
                is_advertisement = score >= 2
            
            logger.info(f"–†–µ–∫–ª–∞–º–Ω—ã–π –ø–∞—Ç—Ç–µ—Ä–Ω: {score}/5 –±–∞–ª–ª–æ–≤, —Ä–µ–∑—É–ª—å—Ç–∞—Ç: {is_advertisement}")
            
            return is_advertisement
            
        except Exception as e:
            logger.error(f"–û—à–∏–±–∫–∞ –æ–ø—Ä–µ–¥–µ–ª–µ–Ω–∏—è —Ä–µ–∫–ª–∞–º–Ω–æ–≥–æ –ø–∞—Ç—Ç–µ—Ä–Ω–∞: {str(e)}")
            return False
    
# Fallback –º–µ—Ç–æ–¥—ã —É–¥–∞–ª–µ–Ω—ã - –∏—Å–ø–æ–ª—å–∑—É–µ–º —Ç–æ–ª—å–∫–æ PaddleOCR
    

    
    async def _extract_characteristics_from_full_image(self, image: np.ndarray) -> FontCharacteristics:
        """–ò–∑–≤–ª–µ—á–µ–Ω–∏–µ —Ö–∞—Ä–∞–∫—Ç–µ—Ä–∏—Å—Ç–∏–∫ –∏–∑ –≤—Å–µ–≥–æ –∏–∑–æ–±—Ä–∞–∂–µ–Ω–∏—è (fallback)"""
        try:
            logger.info("üñºÔ∏è –ê–Ω–∞–ª–∏–∑–∏—Ä—É–µ–º –≤—Å–µ –∏–∑–æ–±—Ä–∞–∂–µ–Ω–∏–µ –∫–∞–∫ fallback")
            
            # –°–æ–∑–¥–∞–µ–º –±–∞–∑–æ–≤—ã–µ —Ö–∞—Ä–∞–∫—Ç–µ—Ä–∏—Å—Ç–∏–∫–∏ –Ω–∞ –æ—Å–Ω–æ–≤–µ —Ä–∞–∑–º–µ—Ä–∞ –∏–∑–æ–±—Ä–∞–∂–µ–Ω–∏—è
            height, width = image.shape[:2]
            
            # –†–ï–ê–õ–¨–ù–´–ï —Ö–∞—Ä–∞–∫—Ç–µ—Ä–∏—Å—Ç–∏–∫–∏ –Ω–∞ –æ—Å–Ω–æ–≤–µ —Å–æ–¥–µ—Ä–∂–∏–º–æ–≥–æ –∏–∑–æ–±—Ä–∞–∂–µ–Ω–∏—è
            # –ê–Ω–∞–ª–∏–∑–∏—Ä—É–µ–º —Å–æ–¥–µ—Ä–∂–∏–º–æ–µ –¥–ª—è —É–Ω–∏–∫–∞–ª—å–Ω–æ—Å—Ç–∏
            try:
                # –ü—ã—Ç–∞–µ–º—Å—è –ø–æ–ª—É—á–∏—Ç—å —Ö–æ—Ç—å –∫–∞–∫—É—é-—Ç–æ –∏–Ω—Ñ–æ—Ä–º–∞—Ü–∏—é –æ —Ç–µ–∫—Å—Ç–µ
                gray = cv2.cvtColor(image, cv2.COLOR_RGB2GRAY) if len(image.shape) == 3 else image
                # –ü—Ä–æ—Å—Ç–∞—è –æ—Ü–µ–Ω–∫–∞ –ø–ª–æ—Ç–Ω–æ—Å—Ç–∏ —Ç–µ–∫—Å—Ç–∞
                text_density = np.sum(gray < 128) / gray.size  # –ü—Ä–æ—Ü–µ–Ω—Ç —Ç–µ–º–Ω—ã—Ö –ø–∏–∫—Å–µ–ª–µ–π
            except:
                text_density = 0.3
            
            # –°–æ–∑–¥–∞–µ–º —É–Ω–∏–∫–∞–ª—å–Ω—ã–π —Ñ–∞–∫—Ç–æ—Ä –Ω–∞ –æ—Å–Ω–æ–≤–µ —Ä–µ–∞–ª—å–Ω–æ–≥–æ —Å–æ–¥–µ—Ä–∂–∏–º–æ–≥–æ
            content_hash = hash(str(image.shape) + str(text_density) + str(width) + str(height))
            unique_factor = (content_hash % 1000) / 1000.0
            
            # –î–ï–¢–ê–õ–¨–ù–û–ï –õ–û–ì–ò–†–û–í–ê–ù–ò–ï FALLBACK –¥–ª—è –æ—Ç–ª–∞–¥–∫–∏
            logger.info(f"üîç FALLBACK –•–ê–†–ê–ö–¢–ï–†–ò–°–¢–ò–ö–ò –ò–ó–û–ë–†–ê–ñ–ï–ù–ò–Ø:")
            logger.info(f"  - –†–∞–∑–º–µ—Ä: {image.shape}")
            logger.info(f"  - –®–∏—Ä–∏–Ω–∞: {width}, –í—ã—Å–æ—Ç–∞: {height}")
            logger.info(f"  - –ü–ª–æ—Ç–Ω–æ—Å—Ç—å —Ç–µ–∫—Å—Ç–∞: {text_density:.3f}")
            logger.info(f"  - –•–µ—à –∏–∑–æ–±—Ä–∞–∂–µ–Ω–∏—è: {content_hash}")
            logger.info(f"  - –£–Ω–∏–∫–∞–ª—å–Ω—ã–π —Ñ–∞–∫—Ç–æ—Ä: {unique_factor:.3f}")  # 0-1
            
            # –°–æ–∑–¥–∞–µ–º –£–ù–ò–ö–ê–õ–¨–ù–´–ï —Ö–∞—Ä–∞–∫—Ç–µ—Ä–∏—Å—Ç–∏–∫–∏ –¥–ª—è –∫–∞–∂–¥–æ–≥–æ –∏–∑–æ–±—Ä–∞–∂–µ–Ω–∏—è
            # –ò—Å–ø–æ–ª—å–∑—É–µ–º —Ä–µ–∞–ª—å–Ω—ã–µ —Ä–∞–∑–º–µ—Ä—ã –∏ —Å–æ–¥–µ—Ä–∂–∏–º–æ–µ
            image_hash = hash(str(image.shape) + str(text_density) + str(width) + str(height))
            unique_factor = (image_hash % 1000) / 1000.0
            
            # –ê–Ω–∞–ª–∏–∑–∏—Ä—É–µ–º —Å–æ–¥–µ—Ä–∂–∏–º–æ–µ –∏–∑–æ–±—Ä–∞–∂–µ–Ω–∏—è –¥–ª—è —É–Ω–∏–∫–∞–ª—å–Ω–æ—Å—Ç–∏
            try:
                # –ü—Ä–æ—Å—Ç–∞—è –æ—Ü–µ–Ω–∫–∞ —Å–ª–æ–∂–Ω–æ—Å—Ç–∏ –∏–∑–æ–±—Ä–∞–∂–µ–Ω–∏—è
                gray = cv2.cvtColor(image, cv2.COLOR_RGB2GRAY) if len(image.shape) == 3 else image
                complexity = np.std(gray.astype(np.float64)) / 255.0  # 0-1
                complexity = min(1.0, max(0.0, complexity))  # –û–≥—Ä–∞–Ω–∏—á–∏–≤–∞–µ–º 0-1
            except:
                complexity = 0.5
            
            # –ë–µ–∑–æ–ø–∞—Å–Ω—ã–µ –≤—ã—á–∏—Å–ª–µ–Ω–∏—è —Å –æ–≥—Ä–∞–Ω–∏—á–µ–Ω–∏—è–º–∏
            safe_stroke_width = min(1.0, max(0.0, text_density * 0.8 + unique_factor * 0.2))
            safe_contrast = min(1.0, max(0.0, complexity + unique_factor * 0.3))
            safe_slant = max(-5.0, min(5.0, (unique_factor - 0.5) * 4.0))  # -5 –¥–æ +5 –≥—Ä–∞–¥—É—Å–æ–≤
            
            characteristics = FontCharacteristics(
                has_serifs=text_density > 0.4 and complexity > 0.3,  # –ù–∞ –æ—Å–Ω–æ–≤–µ –ø–ª–æ—Ç–Ω–æ—Å—Ç–∏ –∏ —Å–ª–æ–∂–Ω–æ—Å—Ç–∏
                stroke_width=safe_stroke_width,  # –ë–µ–∑–æ–ø–∞—Å–Ω–∞—è —Ç–æ–ª—â–∏–Ω–∞
                contrast=safe_contrast,  # –ë–µ–∑–æ–ø–∞—Å–Ω—ã–π –∫–æ–Ω—Ç—Ä–∞—Å—Ç
                slant=safe_slant,  # –ë–µ–∑–æ–ø–∞—Å–Ω—ã–π –Ω–∞–∫–ª–æ–Ω
                cyrillic_features=CyrillicFeatures(),  # –ò—Å–ø–æ–ª—å–∑—É–µ–º –º–æ–¥–µ–ª—å —Å –∑–Ω–∞—á–µ–Ω–∏—è–º–∏ –ø–æ —É–º–æ–ª—á–∞–Ω–∏—é
                x_height=max(1.0, height * (0.5 + unique_factor * 0.2)),  # –ú–∏–Ω–∏–º—É–º 1.0
                cap_height=max(1.0, height * (0.8 + unique_factor * 0.4)),
                ascender=max(1.0, height * (1.0 + unique_factor * 0.4)),
                descender=max(1.0, height * (0.2 + unique_factor * 0.3)),
                letter_spacing=max(0.1, width / (40 + unique_factor * 20)),  # –ú–∏–Ω–∏–º—É–º 0.1
                word_spacing=max(0.1, width / (15 + unique_factor * 10)),
                density=min(1.0, text_density + unique_factor * 0.2)  # –£–Ω–∏–∫–∞–ª—å–Ω–∞—è –ø–ª–æ—Ç–Ω–æ—Å—Ç—å (–º–∞–∫—Å–∏–º—É–º 1.0)
            )
            
            logger.info("‚úÖ –°–æ–∑–¥–∞–Ω—ã –±–∞–∑–æ–≤—ã–µ —Ö–∞—Ä–∞–∫—Ç–µ—Ä–∏—Å—Ç–∏–∫–∏ –¥–ª—è fallback")
            return characteristics
            
        except Exception as e:
            logger.error(f"–û—à–∏–±–∫–∞ fallback –∞–Ω–∞–ª–∏–∑–∞: {str(e)}")
            raise

