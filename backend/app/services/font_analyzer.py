"""
–°–µ—Ä–≤–∏—Å –∞–Ω–∞–ª–∏–∑–∞ —à—Ä–∏—Ñ—Ç–æ–≤ —Å –∏—Å–ø–æ–ª—å–∑–æ–≤–∞–Ω–∏–µ–º PaddleOCR –∏ OpenCV
"""

import cv2
import numpy as np
from PIL import Image
import io
import logging
from typing import Tuple, List, Dict, Any
import asyncio
from concurrent.futures import ThreadPoolExecutor

from ..models.font_models import FontCharacteristics, CyrillicFeatures
from .paddleocr_service import PaddleOCRService

logger = logging.getLogger(__name__)


class FontAnalyzer:
    """–ê–Ω–∞–ª–∏–∑–∞—Ç–æ—Ä —à—Ä–∏—Ñ—Ç–æ–≤ –Ω–∞ –æ—Å–Ω–æ–≤–µ PaddleOCR –∏ OpenCV"""
    
    def __init__(self):
        self.executor = ThreadPoolExecutor(max_workers=4)
        self.paddleocr_service = PaddleOCRService()
        
        # –ü—Ä–æ–≤–µ—Ä—è–µ–º —Å—Ç–∞—Ç—É—Å PaddleOCR
        if self.paddleocr_service.is_available():
            logger.info("‚úÖ FontAnalyzer: PaddleOCR —É—Å–ø–µ—à–Ω–æ –∏–Ω–∏—Ü–∏–∞–ª–∏–∑–∏—Ä–æ–≤–∞–Ω")
        else:
            logger.error("‚ùå FontAnalyzer: PaddleOCR –Ω–µ –∏–Ω–∏—Ü–∏–∞–ª–∏–∑–∏—Ä–æ–≤–∞–Ω - –∞–Ω–∞–ª–∏–∑ —à—Ä–∏—Ñ—Ç–æ–≤ –Ω–µ–≤–æ–∑–º–æ–∂–µ–Ω")
        
    async def analyze_image(self, image_bytes: bytes) -> FontCharacteristics:
        """–ê–Ω–∞–ª–∏–∑ –∏–∑–æ–±—Ä–∞–∂–µ–Ω–∏—è –¥–ª—è –æ–ø—Ä–µ–¥–µ–ª–µ–Ω–∏—è —Ö–∞—Ä–∞–∫—Ç–µ—Ä–∏—Å—Ç–∏–∫ —à—Ä–∏—Ñ—Ç–∞"""
        return await self._analyze_image_async(image_bytes)
    
    async def _analyze_image_async(self, image_bytes: bytes) -> FontCharacteristics:
        """–ê—Å–∏–Ω—Ö—Ä–æ–Ω–Ω—ã–π –∞–Ω–∞–ª–∏–∑ –∏–∑–æ–±—Ä–∞–∂–µ–Ω–∏—è –¢–û–õ–¨–ö–û —á–µ—Ä–µ–∑ PaddleOCR"""
        print("üöÄ –ü–†–ò–ù–£–î–ò–¢–ï–õ–¨–ù–´–ô –í–´–í–û–î: _analyze_image_async –ù–ê–ß–ê–õ–°–Ø")
        logger.info("üöÄ –ü–†–ò–ù–£–î–ò–¢–ï–õ–¨–ù–´–ô –í–´–í–û–î: _analyze_image_async –ù–ê–ß–ê–õ–°–Ø")
        try:
            # –ó–∞–≥—Ä—É–∂–∞–µ–º –∏–∑–æ–±—Ä–∞–∂–µ–Ω–∏–µ
            print("üöÄ –ü–†–ò–ù–£–î–ò–¢–ï–õ–¨–ù–´–ô –í–´–í–û–î: –ó–∞–≥—Ä—É–∂–∞–µ–º –∏–∑–æ–±—Ä–∞–∂–µ–Ω–∏–µ...")
            logger.info("üöÄ –ü–†–ò–ù–£–î–ò–¢–ï–õ–¨–ù–´–ô –í–´–í–û–î: –ó–∞–≥—Ä—É–∂–∞–µ–º –∏–∑–æ–±—Ä–∞–∂–µ–Ω–∏–µ...")
            image = self._load_image(image_bytes)
            
            # –ü—Ä–æ–≤–µ—Ä—è–µ–º –¥–æ—Å—Ç—É–ø–Ω–æ—Å—Ç—å PaddleOCR
            logger.info("=== –ü–†–û–í–ï–†–ö–ê –î–û–°–¢–£–ü–ù–û–°–¢–ò PADDLEOCR ===")
            if not hasattr(self, 'paddleocr_service') or not self.paddleocr_service:
                logger.error("‚ùå PaddleOCR —Å–µ—Ä–≤–∏—Å –Ω–µ–¥–æ—Å—Ç—É–ø–µ–Ω!")
                raise ValueError("–ò–ò –¥–ª—è –∞–Ω–∞–ª–∏–∑–∞ —à—Ä–∏—Ñ—Ç–æ–≤ –≤—Ä–µ–º–µ–Ω–Ω–æ –Ω–µ–¥–æ—Å—Ç—É–ø–µ–Ω. –ü–æ–ø—Ä–æ–±—É–π—Ç–µ –ø–æ–∑–∂–µ –∏–ª–∏ –æ–±—Ä–∞—Ç–∏—Ç–µ—Å—å –∫ –∞–¥–º–∏–Ω–∏—Å—Ç—Ä–∞—Ç–æ—Ä—É.")
            
            if not self.paddleocr_service.is_available():
                logger.error("‚ùå PaddleOCR –Ω–µ –∏–Ω–∏—Ü–∏–∞–ª–∏–∑–∏—Ä–æ–≤–∞–Ω!")
                raise ValueError("–ò–ò –¥–ª—è –∞–Ω–∞–ª–∏–∑–∞ —à—Ä–∏—Ñ—Ç–æ–≤ –≤—Ä–µ–º–µ–Ω–Ω–æ –Ω–µ–¥–æ—Å—Ç—É–ø–µ–Ω. –ü–æ–ø—Ä–æ–±—É–π—Ç–µ –ø–æ–∑–∂–µ –∏–ª–∏ –æ–±—Ä–∞—Ç–∏—Ç–µ—Å—å –∫ –∞–¥–º–∏–Ω–∏—Å—Ç—Ä–∞—Ç–æ—Ä—É.")
            
            logger.info("‚úÖ PaddleOCR –¥–æ—Å—Ç—É–ø–µ–Ω - –Ω–∞—á–∏–Ω–∞–µ–º –∞–Ω–∞–ª–∏–∑")
            
            # –®–ê–ì 1: –û–ø—Ä–µ–¥–µ–ª–µ–Ω–∏–µ –Ω–∞–ª–∏—á–∏—è —Ç–µ–∫—Å—Ç–∞ —á–µ—Ä–µ–∑ PaddleOCR
            logger.info("=== –®–ê–ì 1: –û–ø—Ä–µ–¥–µ–ª–µ–Ω–∏–µ –Ω–∞–ª–∏—á–∏—è —Ç–µ–∫—Å—Ç–∞ —á–µ—Ä–µ–∑ PaddleOCR ===")
            print("üöÄ –ü–†–ò–ù–£–î–ò–¢–ï–õ–¨–ù–´–ô –í–´–í–û–î: –í—ã–∑—ã–≤–∞–µ–º PaddleOCR.analyze_image()")
            logger.info("üöÄ –ü–†–ò–ù–£–î–ò–¢–ï–õ–¨–ù–´–ô –í–´–í–û–î: –í—ã–∑—ã–≤–∞–µ–º PaddleOCR.analyze_image()")
            ocr_result = await self.paddleocr_service.analyze_image(image)
            print(f"üöÄ –ü–†–ò–ù–£–î–ò–¢–ï–õ–¨–ù–´–ô –í–´–í–û–î: PaddleOCR –≤–µ—Ä–Ω—É–ª: {type(ocr_result)}")
            logger.info(f"üöÄ –ü–†–ò–ù–£–î–ò–¢–ï–õ–¨–ù–´–ô –í–´–í–û–î: PaddleOCR –≤–µ—Ä–Ω—É–ª: {type(ocr_result)}")
            
            # –î–ï–¢–ê–õ–¨–ù–û–ï –õ–û–ì–ò–†–û–í–ê–ù–ò–ï OCR —Ä–µ–∑—É–ª—å—Ç–∞—Ç–∞
            logger.info(f"üîç PADDLEOCR –†–ï–ó–£–õ–¨–¢–ê–¢:")
            logger.info(f"  - has_text: {ocr_result.get('has_text', False)}")
            logger.info(f"  - text_content: '{ocr_result.get('text_content', '')[:50]}...'")
            logger.info(f"  - confidence: {ocr_result.get('confidence', 0.0):.3f}")
            logger.info(f"  - regions_count: {ocr_result.get('regions_count', 0)}")
            logger.info(f"  - error: {ocr_result.get('error', '–Ω–µ—Ç')}")
            
            if not ocr_result.get('has_text', False):
                logger.info("–†–ï–ó–£–õ–¨–¢–ê–¢ –®–ê–ì 1: –¢–µ–∫—Å—Ç –Ω–µ –æ–±–Ω–∞—Ä—É–∂–µ–Ω - –°–¢–û–ü")
                error_msg = ocr_result.get('error', 'OCR –Ω–µ —Å–º–æ–≥ –Ω–∞–π—Ç–∏ —Ç–µ–∫—Å—Ç –Ω–∞ –∏–∑–æ–±—Ä–∞–∂–µ–Ω–∏–∏')
                raise ValueError(f"–ù–∞ –∏–∑–æ–±—Ä–∞–∂–µ–Ω–∏–∏ –Ω–µ –æ–±–Ω–∞—Ä—É–∂–µ–Ω —á–∏—Ç–∞–µ–º—ã–π —Ç–µ–∫—Å—Ç: {error_msg}")
            
            logger.info("–†–ï–ó–£–õ–¨–¢–ê–¢ –®–ê–ì 1: ‚úÖ –¢–µ–∫—Å—Ç —É—Å–ø–µ—à–Ω–æ –æ–±–Ω–∞—Ä—É–∂–µ–Ω - –ø—Ä–æ–¥–æ–ª–∂–∞–µ–º")
            
            # –®–ê–ì 2: –ü—Ä–æ–≤–µ—Ä–∫–∞ –º–Ω–æ–∂–µ—Å—Ç–≤–µ–Ω–Ω—ã—Ö —à—Ä–∏—Ñ—Ç–æ–≤ —á–µ—Ä–µ–∑ PaddleOCR
            logger.info("=== –®–ê–ì 2: –ü—Ä–æ–≤–µ—Ä–∫–∞ –º–Ω–æ–∂–µ—Å—Ç–≤–µ–Ω–Ω—ã—Ö —à—Ä–∏—Ñ—Ç–æ–≤ —á–µ—Ä–µ–∑ PaddleOCR ===")
            if await self._detect_multiple_fonts_from_ocr_result(ocr_result):
                logger.info("–†–ï–ó–£–õ–¨–¢–ê–¢ –®–ê–ì 2: –û–±–Ω–∞—Ä—É–∂–µ–Ω–æ –Ω–µ—Å–∫–æ–ª—å–∫–æ —à—Ä–∏—Ñ—Ç–æ–≤ - –°–¢–û–ü")
                raise ValueError("–ù–∞ –∏–∑–æ–±—Ä–∞–∂–µ–Ω–∏–∏ –æ–±–Ω–∞—Ä—É–∂–µ–Ω–æ –Ω–µ—Å–∫–æ–ª—å–∫–æ —Ä–∞–∑–Ω—ã—Ö —à—Ä–∏—Ñ—Ç–æ–≤. –î–ª—è —Ç–æ—á–Ω–æ–≥–æ –∞–Ω–∞–ª–∏–∑–∞ –∑–∞–≥—Ä—É–∑–∏—Ç–µ –∏–∑–æ–±—Ä–∞–∂–µ–Ω–∏–µ —Å —Ç–µ–∫—Å—Ç–æ–º –æ–¥–Ω–æ–≥–æ —à—Ä–∏—Ñ—Ç–∞.")
            logger.info("–†–ï–ó–£–õ–¨–¢–ê–¢ –®–ê–ì 2: ‚úÖ –û–¥–∏–Ω —à—Ä–∏—Ñ—Ç - –ø—Ä–æ–¥–æ–ª–∂–∞–µ–º –∫ –∞–Ω–∞–ª–∏–∑—É")
            
            # –®–ê–ì 3: –ò–∑–≤–ª–µ—á–µ–Ω–∏–µ —Ö–∞—Ä–∞–∫—Ç–µ—Ä–∏—Å—Ç–∏–∫ —à—Ä–∏—Ñ—Ç–∞ —á–µ—Ä–µ–∑ PaddleOCR
            logger.info("=== –®–ê–ì 3: –ò–∑–≤–ª–µ—á–µ–Ω–∏–µ —Ö–∞—Ä–∞–∫—Ç–µ—Ä–∏—Å—Ç–∏–∫ —à—Ä–∏—Ñ—Ç–∞ —á–µ—Ä–µ–∑ PaddleOCR ===")
            characteristics = await self._extract_characteristics_from_ocr(image, ocr_result)
            logger.info("–†–ï–ó–£–õ–¨–¢–ê–¢ –®–ê–ì 3: ‚úÖ –•–∞—Ä–∞–∫—Ç–µ—Ä–∏—Å—Ç–∏–∫–∏ —É—Å–ø–µ—à–Ω–æ –∏–∑–≤–ª–µ—á–µ–Ω—ã")
            
            # –®–ê–ì 4: –°–≤–µ—Ä–∫–∞ —Å –±–∞–∑–æ–π —à—Ä–∏—Ñ—Ç–æ–≤ (–±—É–¥–µ—Ç —Ä–µ–∞–ª–∏–∑–æ–≤–∞–Ω–æ –≤ font_matcher)
            logger.info("=== –®–ê–ì 4: –°–≤–µ—Ä–∫–∞ —Å —Ö–∞—Ä–∞–∫—Ç–µ—Ä–∏—Å—Ç–∏–∫–∞–º–∏ —à—Ä–∏—Ñ—Ç–æ–≤ –≤ –±–∞–∑–µ ===")
            logger.info("–†–ï–ó–£–õ–¨–¢–ê–¢ –®–ê–ì 4: ‚úÖ –ì–æ—Ç–æ–≤–æ –∫ —Å–≤–µ—Ä–∫–µ —Å –±–∞–∑–æ–π (—Ä–µ–∞–ª–∏–∑—É–µ—Ç—Å—è –≤ font_matcher)")
            
            # –®–ê–ì 5: –í—ã–≤–æ–¥ —Ä–µ–∑—É–ª—å—Ç–∞—Ç–æ–≤ –∞–Ω–∞–ª–∏–∑–∞
            logger.info("=== –®–ê–ì 5: –í—ã–≤–æ–¥ —Ä–µ–∑—É–ª—å—Ç–∞—Ç–æ–≤ –∞–Ω–∞–ª–∏–∑–∞ ===")
            logger.info("‚úÖ –ê–Ω–∞–ª–∏–∑ –∑–∞–≤–µ—Ä—à–µ–Ω —É—Å–ø–µ—à–Ω–æ —á–µ—Ä–µ–∑ PaddleOCR")
            print("üöÄ –ü–†–ò–ù–£–î–ò–¢–ï–õ–¨–ù–´–ô –í–´–í–û–î: –ê–Ω–∞–ª–∏–∑ –∑–∞–≤–µ—Ä—à–µ–Ω —É—Å–ø–µ—à–Ω–æ!")
            logger.info("üöÄ –ü–†–ò–ù–£–î–ò–¢–ï–õ–¨–ù–´–ô –í–´–í–û–î: –ê–Ω–∞–ª–∏–∑ –∑–∞–≤–µ—Ä—à–µ–Ω —É—Å–ø–µ—à–Ω–æ!")
            return characteristics
            
        except ValueError as logic_error:
            # –õ–æ–≥–∏—á–µ—Å–∫–∏–µ –æ—à–∏–±–∫–∏ (–Ω–µ—Ç —Ç–µ–∫—Å—Ç–∞, –º–Ω–æ–≥–æ —à—Ä–∏—Ñ—Ç–æ–≤) - –ø–µ—Ä–µ–¥–∞–µ–º –ø–æ–ª—å–∑–æ–≤–∞—Ç–µ–ª—é
            print(f"üöÄ –ü–†–ò–ù–£–î–ò–¢–ï–õ–¨–ù–´–ô –í–´–í–û–î: –õ–æ–≥–∏—á–µ—Å–∫–∞—è –æ—à–∏–±–∫–∞: {str(logic_error)}")
            logger.info(f"‚ÑπÔ∏è –õ–æ–≥–∏—á–µ—Å–∫–∏–π —Ä–µ–∑—É–ª—å—Ç–∞—Ç –∞–Ω–∞–ª–∏–∑–∞: {str(logic_error)}")
            raise logic_error
            
        except Exception as error:
            # –¢–µ—Ö–Ω–∏—á–µ—Å–∫–∏–µ –æ—à–∏–±–∫–∏
            print(f"üöÄ –ü–†–ò–ù–£–î–ò–¢–ï–õ–¨–ù–´–ô –í–´–í–û–î: –¢–µ—Ö–Ω–∏—á–µ—Å–∫–∞—è –æ—à–∏–±–∫–∞: {str(error)}")
            logger.error(f"‚ùå –¢–µ—Ö–Ω–∏—á–µ—Å–∫–∞—è –æ—à–∏–±–∫–∞ –∞–Ω–∞–ª–∏–∑–∞: {str(error)}")
            
            # –û–ø—Ä–µ–¥–µ–ª—è–µ–º —Ç–∏–ø –æ—à–∏–±–∫–∏ –∏ –¥–∞–µ–º –ø–æ–Ω—è—Ç–Ω–æ–µ —Å–æ–æ–±—â–µ–Ω–∏–µ
            if "PaddleOCR –Ω–µ –∏–Ω–∏—Ü–∏–∞–ª–∏–∑–∏—Ä–æ–≤–∞–Ω" in str(error):
                user_message = "–ò–ò –¥–ª—è –∞–Ω–∞–ª–∏–∑–∞ —à—Ä–∏—Ñ—Ç–æ–≤ –≤—Ä–µ–º–µ–Ω–Ω–æ –Ω–µ–¥–æ—Å—Ç—É–ø–µ–Ω. –ü–æ–ø—Ä–æ–±—É–π—Ç–µ –ø–æ–∑–∂–µ –∏–ª–∏ –æ–±—Ä–∞—Ç–∏—Ç–µ—Å—å –∫ –∞–¥–º–∏–Ω–∏—Å—Ç—Ä–∞—Ç–æ—Ä—É."
            elif "PaddleOCR —Å–µ—Ä–≤–∏—Å –Ω–µ–¥–æ—Å—Ç—É–ø–µ–Ω" in str(error):
                user_message = "–°–µ—Ä–≤–∏—Å –∞–Ω–∞–ª–∏–∑–∞ —à—Ä–∏—Ñ—Ç–æ–≤ –≤—Ä–µ–º–µ–Ω–Ω–æ –Ω–µ–¥–æ—Å—Ç—É–ø–µ–Ω. –ü–æ–ø—Ä–æ–±—É–π—Ç–µ –ø–æ–∑–∂–µ."
            elif "–Ω–µ —É–¥–∞–ª–æ—Å—å –∑–∞–≥—Ä—É–∑–∏—Ç—å –∏–∑–æ–±—Ä–∞–∂–µ–Ω–∏–µ" in str(error):
                user_message = "–ù–µ —É–¥–∞–ª–æ—Å—å –æ–±—Ä–∞–±–æ—Ç–∞—Ç—å –∑–∞–≥—Ä—É–∂–µ–Ω–Ω–æ–µ –∏–∑–æ–±—Ä–∞–∂–µ–Ω–∏–µ. –ü—Ä–æ–≤–µ—Ä—å—Ç–µ —Ñ–æ—Ä–º–∞—Ç —Ñ–∞–π–ª–∞."
            else:
                user_message = "–ü—Ä–æ–∏–∑–æ—à–ª–∞ —Ç–µ—Ö–Ω–∏—á–µ—Å–∫–∞—è –æ—à–∏–±–∫–∞ –ø—Ä–∏ –∞–Ω–∞–ª–∏–∑–µ –∏–∑–æ–±—Ä–∞–∂–µ–Ω–∏—è. –ü–æ–ø—Ä–æ–±—É–π—Ç–µ –ø–æ–∑–∂–µ."
            
            raise ValueError(user_message)
    

    
    def _load_image(self, image_bytes: bytes) -> np.ndarray:
        """–ó–∞–≥—Ä—É–∑–∫–∞ –∏–∑–æ–±—Ä–∞–∂–µ–Ω–∏—è –∏–∑ –±–∞–π—Ç–æ–≤"""
        try:
            # –ò—Å–ø–æ–ª—å–∑—É–µ–º PIL –¥–ª—è –∑–∞–≥—Ä—É–∑–∫–∏
            pil_image = Image.open(io.BytesIO(image_bytes))
            
            # –ö–æ–Ω–≤–µ—Ä—Ç–∏—Ä—É–µ–º –≤ RGB –µ—Å–ª–∏ –Ω—É–∂–Ω–æ
            if pil_image.mode != 'RGB':
                pil_image = pil_image.convert('RGB')
            
            # –ö–æ–Ω–≤–µ—Ä—Ç–∏—Ä—É–µ–º –≤ numpy array (RGB –¥–ª—è PaddleOCR)
            cv_image = np.array(pil_image)  # –û—Å—Ç–∞–≤–ª—è–µ–º RGB —Ñ–æ—Ä–º–∞—Ç –¥–ª—è PaddleOCR
            
            logger.info(f"–ò–∑–æ–±—Ä–∞–∂–µ–Ω–∏–µ –∑–∞–≥—Ä—É–∂–µ–Ω–æ: {cv_image.shape}, —Ñ–æ—Ä–º–∞—Ç: RGB")
            return cv_image
            
        except Exception as e:
            logger.error(f"–û—à–∏–±–∫–∞ –∑–∞–≥—Ä—É–∑–∫–∏ –∏–∑–æ–±—Ä–∞–∂–µ–Ω–∏—è: {str(e)}")
            raise ValueError(f"–ù–µ —É–¥–∞–ª–æ—Å—å –∑–∞–≥—Ä—É–∑–∏—Ç—å –∏–∑–æ–±—Ä–∞–∂–µ–Ω–∏–µ: {str(e)}")
    

    

    

    

    

    

    
    async def _detect_multiple_fonts_from_ocr_result(self, ocr_result: dict) -> bool:
        """–î–µ—Ç–µ–∫—Ü–∏—è –º–Ω–æ–∂–µ—Å—Ç–≤–µ–Ω–Ω—ã—Ö —à—Ä–∏—Ñ—Ç–æ–≤ –Ω–∞ –æ—Å–Ω–æ–≤–µ —É–∂–µ –ø–æ–ª—É—á–µ–Ω–Ω–æ–≥–æ OCR —Ä–µ–∑—É–ª—å—Ç–∞—Ç–∞"""
        try:
            logger.info("=== –ê–ù–ê–õ–ò–ó –ú–ù–û–ñ–ï–°–¢–í–ï–ù–ù–´–• –®–†–ò–§–¢–û–í –ü–û OCR –†–ï–ó–£–õ–¨–¢–ê–¢–£ ===")
            
            if not ocr_result.get('has_text', False):
                logger.info("üìä OCR –Ω–µ –Ω–∞—à–µ–ª —Ç–µ–∫—Å—Ç - —Å—á–∏—Ç–∞–µ–º –æ–¥–∏–Ω —à—Ä–∏—Ñ—Ç")
                return False
            
            text_content = ocr_result.get('text_content', '').strip()
            regions_count = ocr_result.get('regions_count', 0)
            ocr_boxes = ocr_result.get('ocr_boxes', [])
            
            logger.info(f"üìä OCR –¥–∞–Ω–Ω—ã–µ: '{text_content[:30]}...' ({regions_count} —Ä–µ–≥–∏–æ–Ω–æ–≤)")
            
            # –ê–Ω–∞–ª–∏–∑–∏—Ä—É–µ–º —Ç–µ–∫—Å—Ç
            words = text_content.split()
            word_count = len(words)
            
            # –ü–†–û–°–¢–´–ï –°–õ–£–ß–ê–ò - –æ–¥–∏–Ω —à—Ä–∏—Ñ—Ç
            if word_count <= 3:
                logger.info(f"üìä –ú–∞–ª–æ —Å–ª–æ–≤ ({word_count}) - –û–î–ò–ù —à—Ä–∏—Ñ—Ç")
                return False
            
            if regions_count < 6:
                logger.info(f"üìä –ú–∞–ª–æ —Ä–µ–≥–∏–æ–Ω–æ–≤ ({regions_count}) - –û–î–ò–ù —à—Ä–∏—Ñ—Ç")
                return False
            
            # –ê–ù–ê–õ–ò–ó –°–û–î–ï–†–ñ–ò–ú–û–ì–û —á–µ—Ä–µ–∑ OCR
            has_title = any(len(word) > 4 and word.isupper() for word in words)
            has_normal_text = any(len(word) > 3 and not word.isupper() for word in words)
            has_numbers = any(char.isdigit() for char in text_content)
            has_special_words = any(word.lower() in ['—Å–∫–∏–¥–∫–∞', '—Ü–µ–Ω–∞', '—Ä—É–±–ª—å', '%', '—Ä—É–±', '—Ä–∞—Å–ø—Ä–æ–¥–∞–∂–∞'] for word in words)
            
            logger.info(f"üìä –ê–Ω–∞–ª–∏–∑ —Å–æ–¥–µ—Ä–∂–∏–º–æ–≥–æ: –∑–∞–≥–æ–ª–æ–≤–æ–∫={has_title}, —Ç–µ–∫—Å—Ç={has_normal_text}, —Ü–∏—Ñ—Ä—ã={has_numbers}, —Å–ø–µ—Ü.—Å–ª–æ–≤–∞={has_special_words}")
            
            # –ê–ù–ê–õ–ò–ó –†–ê–ó–ú–ï–†–û–í –ß–ï–†–ï–ó OCR BOXES
            height_ratio = 1.0
            area_ratio = 1.0
            
            if len(ocr_boxes) >= 4:
                heights = []
                areas = []
                
                for box_info in ocr_boxes:
                    if isinstance(box_info, dict) and 'bbox' in box_info:
                        bbox = box_info['bbox']
                        if isinstance(bbox, list) and len(bbox) >= 4:
                            if isinstance(bbox[0], list):  # –§–æ—Ä–º–∞—Ç [[x1,y1], [x2,y2], ...]
                                x_coords = [point[0] for point in bbox]
                                y_coords = [point[1] for point in bbox]
                            else:  # –§–æ—Ä–º–∞—Ç [x1, y1, x2, y2]
                                x_coords = [bbox[0], bbox[2]]
                                y_coords = [bbox[1], bbox[3]]
                            
                            width = max(x_coords) - min(x_coords)
                            height = max(y_coords) - min(y_coords)
                            
                            if height > 0 and width > 0:
                                heights.append(height)
                                areas.append(width * height)
                
                if len(heights) >= 2:
                    height_ratio = max(heights) / min(heights)
                    area_ratio = max(areas) / min(areas)
                    
                    logger.info(f"üìä OCR —Ä–∞–∑–º–µ—Ä—ã: –≤—ã—Å–æ—Ç–∞={height_ratio:.1f}, –ø–ª–æ—â–∞–¥—å={area_ratio:.1f}")
            
            # –ö–†–ò–¢–ï–†–ò–ò –ú–ù–û–ñ–ï–°–¢–í–ï–ù–ù–´–• –®–†–ò–§–¢–û–í:
            
            # 1. –ü—Ä–æ—Å—Ç—ã–µ —Å–ª—É—á–∞–∏ - —Ç–æ—á–Ω–æ –û–î–ò–ù —à—Ä–∏—Ñ—Ç
            if word_count <= 2 and regions_count <= 3:
                logger.info("üìä –ü—Ä–æ—Å—Ç–æ–π —Å–ª—É—á–∞–π: –æ—á–µ–Ω—å –º–∞–ª–æ —Å–ª–æ–≤ –∏ —Ä–µ–≥–∏–æ–Ω–æ–≤ - –û–î–ò–ù —à—Ä–∏—Ñ—Ç")
                return False
            
            # 2. –°—Ä–µ–¥–Ω—è—è —Å–ª–æ–∂–Ω–æ—Å—Ç—å
            if word_count <= 8 and regions_count <= 10:
                if height_ratio <= 2.5 and area_ratio <= 8.0:
                    logger.info("üìä –°—Ä–µ–¥–Ω—è—è —Å–ª–æ–∂–Ω–æ—Å—Ç—å: —Ä–∞–∑–º–µ—Ä—ã —Å—Ç–∞–±–∏–ª—å–Ω—ã–µ - –û–î–ò–ù —à—Ä–∏—Ñ—Ç")
                    return False
                elif has_title and has_normal_text and height_ratio > 2.5:
                    logger.info("‚úÖ –ú–ù–û–ñ–ï–°–¢–í–ï–ù–ù–´–ï –®–†–ò–§–¢–´: –∑–∞–≥–æ–ª–æ–≤–æ–∫ + —Ç–µ–∫—Å—Ç + —Ä–∞–∑–Ω—ã–µ —Ä–∞–∑–º–µ—Ä—ã")
                    return True
                else:
                    logger.info("üìä –°—Ä–µ–¥–Ω—è—è —Å–ª–æ–∂–Ω–æ—Å—Ç—å: –Ω–µ–æ–ø—Ä–µ–¥–µ–ª–µ–Ω–Ω–æ - —Å—á–∏—Ç–∞–µ–º –û–î–ò–ù —à—Ä–∏—Ñ—Ç")
                    return False
            
            # 3. –°–ª–æ–∂–Ω—ã–µ —Å–ª—É—á–∞–∏
            if word_count > 8 or regions_count > 10:
                if height_ratio > 3.5 and area_ratio > 10.0:
                    logger.info("‚úÖ –ú–ù–û–ñ–ï–°–¢–í–ï–ù–ù–´–ï –®–†–ò–§–¢–´: –±–æ–ª—å—à–∞—è —Ä–∞–∑–Ω–∏—Ü–∞ –≤ —Ä–∞–∑–º–µ—Ä–∞—Ö")
                    return True
                elif has_title and has_normal_text and height_ratio > 2.2 and word_count >= 10:
                    logger.info("‚úÖ –ú–ù–û–ñ–ï–°–¢–í–ï–ù–ù–´–ï –®–†–ò–§–¢–´: –∑–∞–≥–æ–ª–æ–≤–æ–∫ + –º–Ω–æ–≥–æ —Ç–µ–∫—Å—Ç–∞ + —Ä–∞–∑–Ω—ã–µ —Ä–∞–∑–º–µ—Ä—ã")
                    return True
                elif height_ratio > 3.0 and regions_count >= 15:
                    logger.info("‚úÖ –ú–ù–û–ñ–ï–°–¢–í–ï–ù–ù–´–ï –®–†–ò–§–¢–´: –º–Ω–æ–≥–æ —Ä–µ–≥–∏–æ–Ω–æ–≤ + –∑–∞–º–µ—Ç–Ω–∞—è —Ä–∞–∑–Ω–∏—Ü–∞ —Ä–∞–∑–º–µ—Ä–æ–≤")
                    return True
                elif has_numbers and has_normal_text and height_ratio > 2.8:
                    logger.info("‚úÖ –ú–ù–û–ñ–ï–°–¢–í–ï–ù–ù–´–ï –®–†–ò–§–¢–´: —Ü–∏—Ñ—Ä—ã + —Ç–µ–∫—Å—Ç + —Ä–∞–∑–Ω—ã–µ —Ä–∞–∑–º–µ—Ä—ã")
                    return True
                else:
                    logger.info("üìä –°–ª–æ–∂–Ω—ã–π —Å–ª—É—á–∞–π: –Ω–µ–æ–ø—Ä–µ–¥–µ–ª–µ–Ω–Ω–æ - —Å—á–∏—Ç–∞–µ–º –û–î–ò–ù —à—Ä–∏—Ñ—Ç")
                    return False
            
            # –ü–æ —É–º–æ–ª—á–∞–Ω–∏—é —Å—á–∏—Ç–∞–µ–º –æ–¥–∏–Ω —à—Ä–∏—Ñ—Ç
            logger.info("üìä –ü–æ —É–º–æ–ª—á–∞–Ω–∏—é: —Å—á–∏—Ç–∞–µ–º –û–î–ò–ù —à—Ä–∏—Ñ—Ç")
            return False
            
        except Exception as e:
            logger.error(f"–û—à–∏–±–∫–∞ –∞–Ω–∞–ª–∏–∑–∞ –º–Ω–æ–∂–µ—Å—Ç–≤–µ–Ω–Ω—ã—Ö —à—Ä–∏—Ñ—Ç–æ–≤: {str(e)}")
            logger.warning("‚ö†Ô∏è –ü—Ä–∏ –æ—à–∏–±–∫–µ —Å—á–∏—Ç–∞–µ–º –æ–¥–∏–Ω —à—Ä–∏—Ñ—Ç")
            return False
    
    def _get_ocr_based_characteristics(self, ocr_result: dict) -> dict:
        """–ò–∑–≤–ª–µ—á–µ–Ω–∏–µ —Ö–∞—Ä–∞–∫—Ç–µ—Ä–∏—Å—Ç–∏–∫ –¢–û–õ–¨–ö–û –∏–∑ OCR —Ä–µ–∑—É–ª—å—Ç–∞—Ç–æ–≤"""
        try:
            logger.info("=== –ò–ó–í–õ–ï–ß–ï–ù–ò–ï –•–ê–†–ê–ö–¢–ï–†–ò–°–¢–ò–ö –ò–ó OCR ===")
            
            text_content = ocr_result.get('text_content', '').strip()
            regions_count = ocr_result.get('regions_count', 0)
            ocr_boxes = ocr_result.get('ocr_boxes', [])
            
            # –ê–Ω–∞–ª–∏–∑ —Ç–µ–∫—Å—Ç–∞
            words = text_content.split()
            word_count = len(words)
            avg_word_length = np.mean([len(word) for word in words]) if words else 0
            
            # –ê–Ω–∞–ª–∏–∑ —Ä–∞–∑–º–µ—Ä–æ–≤ –∏–∑ OCR boxes
            heights = []
            widths = []
            areas = []
            
            for box_info in ocr_boxes:
                if isinstance(box_info, list) and len(box_info) >= 2:
                    box = box_info[0]  # –∫–æ–æ—Ä–¥–∏–Ω–∞—Ç—ã
                    if isinstance(box, list) and len(box) >= 4:
                        # –í—ã—á–∏—Å–ª—è–µ–º —Ä–∞–∑–º–µ—Ä—ã box
                        x_coords = [point[0] for point in box]
                        y_coords = [point[1] for point in box]
                        
                        width = max(x_coords) - min(x_coords)
                        height = max(y_coords) - min(y_coords)
                        
                        heights.append(height)
                        widths.append(width)
                        areas.append(width * height)
            
            # –•–∞—Ä–∞–∫—Ç–µ—Ä–∏—Å—Ç–∏–∫–∏ –Ω–∞ –æ—Å–Ω–æ–≤–µ OCR –¥–∞–Ω–Ω—ã—Ö
            characteristics = {
                'text_length': len(text_content),
                'word_count': word_count,
                'regions_count': regions_count,
                'avg_word_length': avg_word_length,
                'avg_height': np.mean(heights) if heights else 20.0,
                'avg_width': np.mean(widths) if widths else 100.0,
                'avg_area': np.mean(areas) if areas else 2000.0,
                'height_variance': np.var(heights) if len(heights) > 1 else 0.0,
                'width_variance': np.var(widths) if len(widths) > 1 else 0.0,
                'has_uppercase': any(c.isupper() for c in text_content),
                'has_lowercase': any(c.islower() for c in text_content),
                'has_numbers': any(c.isdigit() for c in text_content),
                'has_cyrillic': any(ord(c) >= 1040 and ord(c) <= 1103 for c in text_content),
                'text_density': word_count / max(regions_count, 1)  # —Å–ª–æ–≤ –Ω–∞ —Ä–µ–≥–∏–æ–Ω
            }
            
            logger.info(f"OCR —Ö–∞—Ä–∞–∫—Ç–µ—Ä–∏—Å—Ç–∏–∫–∏: {characteristics}")
            return characteristics
            
        except Exception as e:
            logger.error(f"–û—à–∏–±–∫–∞ –∏–∑–≤–ª–µ—á–µ–Ω–∏—è OCR —Ö–∞—Ä–∞–∫—Ç–µ—Ä–∏—Å—Ç–∏–∫: {str(e)}")
            return self._get_default_ocr_characteristics()
    
    def _get_default_ocr_characteristics(self) -> dict:
        """OCR —Ö–∞—Ä–∞–∫—Ç–µ—Ä–∏—Å—Ç–∏–∫–∏ –ø–æ —É–º–æ–ª—á–∞–Ω–∏—é"""
        return {
            'text_length': 0,
            'word_count': 0,
            'regions_count': 0,
            'avg_word_length': 0,
            'avg_height': 20.0,
            'avg_width': 100.0,
            'avg_area': 2000.0,
            'height_variance': 0.0,
            'width_variance': 0.0,
            'has_uppercase': False,
            'has_lowercase': False,
            'has_numbers': False,
            'has_cyrillic': False,
            'text_density': 0.0
        }
    
    def _binarize_image(self, gray: np.ndarray) -> np.ndarray:
        """–ë–∏–Ω–∞—Ä–∏–∑–∞—Ü–∏—è –∏–∑–æ–±—Ä–∞–∂–µ–Ω–∏—è"""
        # –ò—Å–ø–æ–ª—å–∑—É–µ–º –∞–¥–∞–ø—Ç–∏–≤–Ω—É—é –±–∏–Ω–∞—Ä–∏–∑–∞—Ü–∏—é –¥–ª—è –ª—É—á—à–µ–≥–æ —Ä–µ–∑—É–ª—å—Ç–∞—Ç–∞
        binary = cv2.adaptiveThreshold(
            gray, 255, cv2.ADAPTIVE_THRESH_GAUSSIAN_C, cv2.THRESH_BINARY, 11, 2
        )
        return binary
    
    async def _extract_characteristics_from_ocr(self, image: np.ndarray, ocr_result: dict) -> FontCharacteristics:
        """–ò–∑–≤–ª–µ—á–µ–Ω–∏–µ —Ö–∞—Ä–∞–∫—Ç–µ—Ä–∏—Å—Ç–∏–∫ —à—Ä–∏—Ñ—Ç–∞ –¢–û–õ–¨–ö–û –∏–∑ OCR"""
        
        logger.info("=== –ò–ó–í–õ–ï–ß–ï–ù–ò–ï –•–ê–†–ê–ö–¢–ï–†–ò–°–¢–ò–ö –ß–ï–†–ï–ó OCR ===")
        
        # OCR —Ä–µ–∑—É–ª—å—Ç–∞—Ç —É–∂–µ –ø–æ–ª—É—á–µ–Ω –≤ –≤—ã–∑—ã–≤–∞—é—â–µ–º –º–µ—Ç–æ–¥–µ
        logger.info("üìä –ò—Å–ø–æ–ª—å–∑—É–µ–º –ø–µ—Ä–µ–¥–∞–Ω–Ω—ã–π OCR —Ä–µ–∑—É–ª—å—Ç–∞—Ç")
        
        # –î–û–ü–û–õ–ù–ò–¢–ï–õ–¨–ù–ê–Ø –ø—Ä–æ–≤–µ—Ä–∫–∞ –Ω–∞ –æ—Ç—Å—É—Ç—Å—Ç–≤–∏–µ —Ç–µ–∫—Å—Ç–∞
        text_content = ocr_result.get('text_content', '').strip()
        if not text_content or len(text_content) < 2:
            logger.warning("‚ö†Ô∏è OCR –≤–µ—Ä–Ω—É–ª –ø—É—Å—Ç–æ–π –∏–ª–∏ —Å–ª–∏—à–∫–æ–º –∫–æ—Ä–æ—Ç–∫–∏–π —Ç–µ–∫—Å—Ç")
            raise ValueError("–ù–∞ –∏–∑–æ–±—Ä–∞–∂–µ–Ω–∏–∏ –Ω–µ –æ–±–Ω–∞—Ä—É–∂–µ–Ω —á–∏—Ç–∞–µ–º—ã–π —Ç–µ–∫—Å—Ç –¥–ª—è –∞–Ω–∞–ª–∏–∑–∞")
        
        # –ü—Ä–æ–≤–µ—Ä—è–µ–º –∫–∞—á–µ—Å—Ç–≤–æ —Ä–∞—Å–ø–æ–∑–Ω–∞–≤–∞–Ω–∏—è
        confidence = ocr_result.get('confidence', 0.0)
        if confidence < 0.3:  # –ù–∏–∑–∫–∞—è —É–≤–µ—Ä–µ–Ω–Ω–æ—Å—Ç—å
            logger.warning(f"‚ö†Ô∏è –ù–∏–∑–∫–∞—è —É–≤–µ—Ä–µ–Ω–Ω–æ—Å—Ç—å OCR: {confidence:.2f}")
            raise ValueError("OCR –Ω–µ —Å–º–æ–≥ —É–≤–µ—Ä–µ–Ω–Ω–æ —Ä–∞—Å–ø–æ–∑–Ω–∞—Ç—å —Ç–µ–∫—Å—Ç –Ω–∞ –∏–∑–æ–±—Ä–∞–∂–µ–Ω–∏–∏")
        
        # –ü–æ–ª—É—á–∞–µ–º OCR —Ö–∞—Ä–∞–∫—Ç–µ—Ä–∏—Å—Ç–∏–∫–∏
        ocr_chars = self._get_ocr_based_characteristics(ocr_result)
        
        # –ö–æ–Ω–≤–µ—Ä—Ç–∏—Ä—É–µ–º –≤ FontCharacteristics –Ω–∞ –æ—Å–Ω–æ–≤–µ OCR –¥–∞–Ω–Ω—ã—Ö
        text_content = ocr_result.get('text_content', '').strip()
        
        # –ê–Ω–∞–ª–∏–∑–∏—Ä—É–µ–º —Ç–∏–ø —à—Ä–∏—Ñ—Ç–∞ –ø–æ —Å–æ–¥–µ—Ä–∂–∏–º–æ–º—É –∏ —Ä–∞–∑–º–µ—Ä–∞–º
        has_serifs = self._predict_serifs_from_ocr(ocr_chars, text_content)
        
        # –†–ï–ê–õ–¨–ù–´–ï —Ö–∞—Ä–∞–∫—Ç–µ—Ä–∏—Å—Ç–∏–∫–∏ –Ω–∞ –æ—Å–Ω–æ–≤–µ —Å–æ–¥–µ—Ä–∂–∏–º–æ–≥–æ –∏–∑–æ–±—Ä–∞–∂–µ–Ω–∏—è
        # stroke_width –Ω–∞ –æ—Å–Ω–æ–≤–µ —Ä–µ–∞–ª—å–Ω–æ–π —Ç–æ–ª—â–∏–Ω—ã —Ç–µ–∫—Å—Ç–∞
        if ocr_chars['avg_height'] > 0:
            # –ù–æ—Ä–º–∞–ª–∏–∑—É–µ–º —Ç–æ–ª—â–∏–Ω—É –æ—Ç–Ω–æ—Å–∏—Ç–µ–ª—å–Ω–æ —Ä–∞–∑–º–µ—Ä–∞ —Ç–µ–∫—Å—Ç–∞
            stroke_width = min(1.0, max(0.0, ocr_chars['avg_height'] / 50.0))
        else:
            stroke_width = 0.5
        
        # contrast –Ω–∞ –æ—Å–Ω–æ–≤–µ —Ä–µ–∞–ª—å–Ω–æ–π –≤–∞—Ä–∏–∞—Ç–∏–≤–Ω–æ—Å—Ç–∏ —Ä–∞–∑–º–µ—Ä–æ–≤
        if ocr_chars['height_variance'] > 0 and ocr_chars['avg_height'] > 0:
            # –ù–æ—Ä–º–∞–ª–∏–∑—É–µ–º –∫–æ–Ω—Ç—Ä–∞—Å—Ç
            contrast = min(1.0, max(0.0, ocr_chars['height_variance'] / ocr_chars['avg_height']))
        else:
            contrast = 0.3
        
        # –ù–∞–∫–ª–æ–Ω –Ω–∞ –æ—Å–Ω–æ–≤–µ —Ä–µ–∞–ª—å–Ω–æ–≥–æ —Å–æ–¥–µ—Ä–∂–∏–º–æ–≥–æ
        # –ê–Ω–∞–ª–∏–∑–∏—Ä—É–µ–º —Ç–µ–∫—Å—Ç –Ω–∞ –ø—Ä–µ–¥–º–µ—Ç –Ω–∞–∫–ª–æ–Ω–∞
        slant = 0.0  # –ü–æ–∫–∞ –±–µ–∑ –∞–Ω–∞–ª–∏–∑–∞ –Ω–∞–∫–ª–æ–Ω–∞
        
        # –£–Ω–∏–∫–∞–ª—å–Ω–æ—Å—Ç—å —á–µ—Ä–µ–∑ —Ä–µ–∞–ª—å–Ω–æ–µ —Å–æ–¥–µ—Ä–∂–∏–º–æ–µ –∏–∑–æ–±—Ä–∞–∂–µ–Ω–∏—è
        content_hash = hash(text_content + str(ocr_chars['regions_count']) + str(ocr_chars['avg_height']))
        unique_factor = (content_hash % 1000) / 1000.0
        
        # –î–ï–¢–ê–õ–¨–ù–û–ï –õ–û–ì–ò–†–û–í–ê–ù–ò–ï –¥–ª—è –æ—Ç–ª–∞–¥–∫–∏
        logger.info(f"üîç –£–ù–ò–ö–ê–õ–¨–ù–´–ï –•–ê–†–ê–ö–¢–ï–†–ò–°–¢–ò–ö–ò –ò–ó–û–ë–†–ê–ñ–ï–ù–ò–Ø:")
        logger.info(f"  - –¢–µ–∫—Å—Ç: '{text_content[:50]}...' (–¥–ª–∏–Ω–∞: {len(text_content)})")
        logger.info(f"  - –†–µ–≥–∏–æ–Ω—ã: {ocr_chars['regions_count']}")
        logger.info(f"  - –°—Ä–µ–¥–Ω—è—è –≤—ã—Å–æ—Ç–∞: {ocr_chars['avg_height']:.2f}")
        logger.info(f"  - –•–µ—à —Å–æ–¥–µ—Ä–∂–∏–º–æ–≥–æ: {content_hash}")
        logger.info(f"  - –£–Ω–∏–∫–∞–ª—å–Ω—ã–π —Ñ–∞–∫—Ç–æ—Ä: {unique_factor:.3f}")
        logger.info(f"  - stroke_width: {stroke_width:.3f}")
        logger.info(f"  - contrast: {contrast:.3f}")
        logger.info(f"  - slant: {slant:.3f}")
        
        # –ì–µ–æ–º–µ—Ç—Ä–∏—á–µ—Å–∫–∏–µ —Ö–∞—Ä–∞–∫—Ç–µ—Ä–∏—Å—Ç–∏–∫–∏ –∏–∑ OCR
        avg_height = ocr_chars['avg_height']
        x_height = avg_height * 0.6  # –ü—Ä–∏–º–µ—Ä–Ω–∞—è –ø—Ä–æ–ø–æ—Ä—Ü–∏—è
        cap_height = avg_height
        ascender = avg_height * 1.2
        descender = avg_height * 0.3
        
        # –ò–Ω—Ç–µ—Ä–≤–∞–ª—ã –Ω–∞ –æ—Å–Ω–æ–≤–µ –ø–ª–æ—Ç–Ω–æ—Å—Ç–∏ —Ç–µ–∫—Å—Ç–∞
        letter_spacing = ocr_chars['avg_width'] / max(ocr_chars['avg_word_length'], 1) * 0.1
        word_spacing = ocr_chars['avg_width'] * 0.3
        density = ocr_chars['text_density']
        
        # –ö–∏—Ä–∏–ª–ª–∏—á–µ—Å–∫–∏–µ –æ—Å–æ–±–µ–Ω–Ω–æ—Å—Ç–∏
        cyrillic_features = {
            'has_cyrillic': ocr_chars['has_cyrillic'],
            'cyrillic_ratio': 1.0 if ocr_chars['has_cyrillic'] else 0.0,
            'specific_letters': []
        }
        
        logger.info(f"OCR —Ö–∞—Ä–∞–∫—Ç–µ—Ä–∏—Å—Ç–∏–∫–∏ —à—Ä–∏—Ñ—Ç–∞: –∑–∞—Å–µ—á–∫–∏={has_serifs}, —Ç–æ–ª—â–∏–Ω–∞={stroke_width:.1f}, –≤—ã—Å–æ—Ç–∞={avg_height:.1f}")
        
        return FontCharacteristics(
            has_serifs=has_serifs,
            stroke_width=stroke_width,
            contrast=contrast,
            slant=slant,
            cyrillic_features=cyrillic_features,
            x_height=x_height,
            cap_height=cap_height,
            ascender=ascender,
            descender=descender,
            letter_spacing=letter_spacing,
            word_spacing=word_spacing,
            density=density
        )
    
    def _predict_serifs_from_ocr(self, ocr_chars: dict, text_content: str) -> bool:
        """–ü—Ä–µ–¥—Å–∫–∞–∑–∞–Ω–∏–µ –Ω–∞–ª–∏—á–∏—è –∑–∞—Å–µ—á–µ–∫ –Ω–∞ –æ—Å–Ω–æ–≤–µ OCR –¥–∞–Ω–Ω—ã—Ö"""
        # –≠–≤—Ä–∏—Å—Ç–∏–∫–∞: –µ—Å–ª–∏ —Ç–µ–∫—Å—Ç —Ñ–æ—Ä–º–∞–ª—å–Ω—ã–π –∏ —Ä–∞–∑–º–µ—Ä—ã —Å—Ç–∞–±–∏–ª—å–Ω—ã–µ - –≤–æ–∑–º–æ–∂–Ω–æ –∑–∞—Å–µ—á–∫–∏
        has_formal_text = any(word.lower() in ['–æ—Ñ–∏—Ü–∏–∞–ª—å–Ω—ã–π', '–¥–æ–∫—É–º–µ–Ω—Ç', '–∫–Ω–∏–≥–∞', '—Å—Ç–∞—Ç—å—è'] for word in text_content.split())
        stable_sizes = ocr_chars['height_variance'] < ocr_chars['avg_height'] * 0.2
        
        return has_formal_text and stable_sizes
    
    def _detect_serifs(self, binary: np.ndarray) -> bool:
        """–û–ø—Ä–µ–¥–µ–ª–µ–Ω–∏–µ –Ω–∞–ª–∏—á–∏—è –∑–∞—Å–µ—á–µ–∫"""
        # –ü—Ä–∏–º–µ–Ω—è–µ–º –º–æ—Ä—Ñ–æ–ª–æ–≥–∏—á–µ—Å–∫–∏–µ –æ–ø–µ—Ä–∞—Ü–∏–∏ –¥–ª—è –≤—ã–¥–µ–ª–µ–Ω–∏—è –º–µ–ª–∫–∏—Ö –¥–µ—Ç–∞–ª–µ–π
        kernel = cv2.getStructuringElement(cv2.MORPH_RECT, (3, 3))
        opened = cv2.morphologyEx(binary, cv2.MORPH_OPEN, kernel)
        
        # –ù–∞—Ö–æ–¥–∏–º —Ä–∞–∑–Ω–æ—Å—Ç—å - –º–µ–ª–∫–∏–µ –¥–µ—Ç–∞–ª–∏ (–ø–æ—Ç–µ–Ω—Ü–∏–∞–ª—å–Ω—ã–µ –∑–∞—Å–µ—á–∫–∏)
        diff = cv2.absdiff(binary, opened)
        serif_pixels = np.sum(diff == 255)
        total_text_pixels = np.sum(binary == 0)  # –ß–µ—Ä–Ω—ã–µ –ø–∏–∫—Å–µ–ª–∏ –≤ –±–∏–Ω–∞—Ä–Ω–æ–º –∏–∑–æ–±—Ä–∞–∂–µ–Ω–∏–∏
        
        if total_text_pixels == 0:
            return False
        
        serif_ratio = serif_pixels / total_text_pixels
        has_serifs = serif_ratio > 0.05  # –≠–º–ø–∏—Ä–∏—á–µ—Å–∫–∏–π –ø–æ—Ä–æ–≥
        
        logger.info(f"–ê–Ω–∞–ª–∏–∑ –∑–∞—Å–µ—á–µ–∫: —Å–æ–æ—Ç–Ω–æ—à–µ–Ω–∏–µ={serif_ratio:.3f}, —Ä–µ–∑—É–ª—å—Ç–∞—Ç={has_serifs}")
        return has_serifs
    
    def _analyze_stroke_width(self, binary: np.ndarray) -> float:
        """–ê–Ω–∞–ª–∏–∑ —Ç–æ–ª—â–∏–Ω—ã —à—Ç—Ä–∏—Ö–æ–≤"""
        # –ò—Å–ø–æ–ª—å–∑—É–µ–º —Ä–∞—Å—Å—Ç–æ—è–Ω–∏–µ –¥–æ –±–ª–∏–∂–∞–π—à–µ–≥–æ –Ω—É–ª—è (distance transform)
        dist_transform = cv2.distanceTransform(255 - binary, cv2.DIST_L2, 5)
        
        # –ù–∞—Ö–æ–¥–∏–º —Å—Ä–µ–¥–Ω—é—é —Ç–æ–ª—â–∏–Ω—É —à—Ç—Ä–∏—Ö–æ–≤
        text_pixels = binary == 0
        if np.sum(text_pixels) == 0:
            return 0.1
        
        avg_thickness = np.mean(dist_transform[text_pixels]) * 2  # –£–º–Ω–æ–∂–∞–µ–º –Ω–∞ 2 –¥–ª—è –ø–æ–ª–Ω–æ–π —à–∏—Ä–∏–Ω—ã
        
        # –ù–æ—Ä–º–∞–ª–∏–∑—É–µ–º –æ—Ç–Ω–æ—Å–∏—Ç–µ–ª—å–Ω–æ —Ä–∞–∑–º–µ—Ä–∞ –∏–∑–æ–±—Ä–∞–∂–µ–Ω–∏—è
        normalized_thickness = avg_thickness / max(binary.shape)
        
        # –î–æ–ø–æ–ª–Ω–∏—Ç–µ–ª—å–Ω–∞—è –Ω–æ—Ä–º–∞–ª–∏–∑–∞—Ü–∏—è –¥–ª—è –≥–∞—Ä–∞–Ω—Ç–∏–∏ –¥–∏–∞–ø–∞–∑–æ–Ω–∞ [0, 1]
        normalized_thickness = normalized_thickness / 10.0  # –î–µ–ª–∏–º –Ω–∞ 10 –¥–ª—è –±–æ–ª–µ–µ —Ä–µ–∞–ª–∏—Å—Ç–∏—á–Ω—ã—Ö –∑–Ω–∞—á–µ–Ω–∏–π
        
        return min(1.0, max(0.0, normalized_thickness))
    
    def _analyze_contrast(self, gray: np.ndarray) -> float:
        """–ê–Ω–∞–ª–∏–∑ –∫–æ–Ω—Ç—Ä–∞—Å—Ç–∞"""
        # –í—ã—á–∏—Å–ª—è–µ–º —Å—Ç–∞–Ω–¥–∞—Ä—Ç–Ω–æ–µ –æ—Ç–∫–ª–æ–Ω–µ–Ω–∏–µ –∫–∞–∫ –º–µ—Ä—É –∫–æ–Ω—Ç—Ä–∞—Å—Ç–∞
        std_dev = np.std(gray)
        
        # –ù–æ—Ä–º–∞–ª–∏–∑—É–µ–º –∫ –¥–∏–∞–ø–∞–∑–æ–Ω—É 0-1
        contrast = std_dev / 128.0
        
        return min(1.0, max(0.0, contrast))
    
    def _analyze_slant(self, binary: np.ndarray) -> float:
        """–ê–Ω–∞–ª–∏–∑ –Ω–∞–∫–ª–æ–Ω–∞ —Ç–µ–∫—Å—Ç–∞"""
        # –ò—Å–ø–æ–ª—å–∑—É–µ–º –ø—Ä–µ–æ–±—Ä–∞–∑–æ–≤–∞–Ω–∏–µ –•–∞—Ñ–∞ –¥–ª—è –ø–æ–∏—Å–∫–∞ –¥–æ–º–∏–Ω–∏—Ä—É—é—â–∏—Ö –ª–∏–Ω–∏–π
        edges = cv2.Canny(binary, 50, 150)
        lines = cv2.HoughLines(edges, 1, np.pi/180, threshold=50)
        
        if lines is None:
            return 0.0
        
        angles = []
        for line in lines[:20]:  # –ë–µ—Ä–µ–º –ø–µ—Ä–≤—ã–µ 20 –ª–∏–Ω–∏–π
            rho, theta = line[0]
            angle = theta * 180 / np.pi
            
            # –ò–Ω—Ç–µ—Ä–µ—Å—É—é—Ç –≤–µ—Ä—Ç–∏–∫–∞–ª—å–Ω—ã–µ –ª–∏–Ω–∏–∏ (–æ–∫–æ–ª–æ 90 –≥—Ä–∞–¥—É—Å–æ–≤)
            if 80 <= angle <= 100:
                angles.append(angle - 90)
        
        if not angles:
            return 0.0
        
        # –í–æ–∑–≤—Ä–∞—â–∞–µ–º —Å—Ä–µ–¥–Ω–∏–π –Ω–∞–∫–ª–æ–Ω
        return np.mean(angles)
    
    def _analyze_geometry(self, binary: np.ndarray) -> Tuple[float, float, float, float]:
        """–ê–Ω–∞–ª–∏–∑ –≥–µ–æ–º–µ—Ç—Ä–∏—á–µ—Å–∫–∏—Ö —Ö–∞—Ä–∞–∫—Ç–µ—Ä–∏—Å—Ç–∏–∫"""
        # –ù–∞—Ö–æ–¥–∏–º –∫–æ–Ω—Ç—É—Ä—ã –±—É–∫–≤
        contours, _ = cv2.findContours(binary, cv2.RETR_EXTERNAL, cv2.CHAIN_APPROX_SIMPLE)
        
        if not contours:
            return 50.0, 70.0, 80.0, 20.0
        
        # –ê–Ω–∞–ª–∏–∑–∏—Ä—É–µ–º –≤—ã—Å–æ—Ç—ã –±—É–∫–≤
        heights = []
        for contour in contours:
            _, _, _, h = cv2.boundingRect(contour)
            if h > 10:  # –§–∏–ª—å—Ç—Ä—É–µ–º —Å–ª–∏—à–∫–æ–º –º–∞–ª–µ–Ω—å–∫–∏–µ –∫–æ–Ω—Ç—É—Ä—ã
                heights.append(h)
        
        if not heights:
            return 50.0, 70.0, 80.0, 20.0
        
        # –≠–º–ø–∏—Ä–∏—á–µ—Å–∫–∏–µ —Å–æ–æ—Ç–Ω–æ—à–µ–Ω–∏—è –¥–ª—è –∫–∏—Ä–∏–ª–ª–∏—á–µ—Å–∫–∏—Ö —à—Ä–∏—Ñ—Ç–æ–≤
        avg_height = np.mean(heights)
        x_height = avg_height * 0.5
        cap_height = avg_height * 0.7
        ascender = avg_height * 0.8
        descender = avg_height * 0.2
        
        return x_height, cap_height, ascender, descender
    
    def _analyze_spacing(self, binary: np.ndarray) -> Tuple[float, float]:
        """–ê–Ω–∞–ª–∏–∑ –º–µ–∂–±—É–∫–≤–µ–Ω–Ω—ã—Ö –∏ –º–µ–∂—Å–ª–æ–≤–Ω—ã—Ö —Ä–∞—Å—Å—Ç–æ—è–Ω–∏–π"""
        # –£–ø—Ä–æ—â–µ–Ω–Ω—ã–π –∞–Ω–∞–ª–∏–∑ - –≤ —Ä–µ–∞–ª—å–Ω–æ—Å—Ç–∏ –Ω—É–∂–µ–Ω –±–æ–ª–µ–µ —Å–ª–æ–∂–Ω—ã–π –∞–ª–≥–æ—Ä–∏—Ç–º
        height, width = binary.shape
        
        # –ê–Ω–∞–ª–∏–∑–∏—Ä—É–µ–º –≥–æ—Ä–∏–∑–æ–Ω—Ç–∞–ª—å–Ω—ã–µ –ø—Ä–æ–µ–∫—Ü–∏–∏ –¥–ª—è –æ–ø—Ä–µ–¥–µ–ª–µ–Ω–∏—è —Ä–∞—Å—Å—Ç–æ—è–Ω–∏–π
        horizontal_projection = np.sum(binary == 0, axis=0)
        
        # –ù–∞—Ö–æ–¥–∏–º –ø—Ä–æ–º–µ–∂—É—Ç–∫–∏ –º–µ–∂–¥—É –±—É–∫–≤–∞–º–∏
        gaps = []
        in_gap = False
        gap_start = 0
        
        for i, projection in enumerate(horizontal_projection):
            if projection == 0 and not in_gap:  # –ù–∞—á–∞–ª–æ –ø—Ä–æ–º–µ–∂—É—Ç–∫–∞
                in_gap = True
                gap_start = i
            elif projection > 0 and in_gap:  # –ö–æ–Ω–µ—Ü –ø—Ä–æ–º–µ–∂—É—Ç–∫–∞
                gaps.append(i - gap_start)
                in_gap = False
        
        if gaps:
            letter_spacing = np.mean(gaps)
            word_spacing = np.percentile(gaps, 75) if len(gaps) > 1 else letter_spacing * 2
        else:
            letter_spacing = 2.0
            word_spacing = 6.0
        
        return letter_spacing, word_spacing
    
    def _calculate_density(self, binary: np.ndarray) -> float:
        """–†–∞—Å—á–µ—Ç –ø–ª–æ—Ç–Ω–æ—Å—Ç–∏ —Ç–µ–∫—Å—Ç–∞"""
        text_pixels = np.sum(binary == 0)
        total_pixels = binary.shape[0] * binary.shape[1]
        
        return text_pixels / total_pixels if total_pixels > 0 else 0.0
    
    def _analyze_cyrillic_features(self, binary: np.ndarray) -> CyrillicFeatures:
        """
        –ê–Ω–∞–ª–∏–∑ –æ—Å–æ–±–µ–Ω–Ω–æ—Å—Ç–µ–π –∫–∏—Ä–∏–ª–ª–∏—á–µ—Å–∫–∏—Ö –±—É–∫–≤
        –£–ø—Ä–æ—â–µ–Ω–Ω–∞—è –≤–µ—Ä—Å–∏—è - –≤ —Ä–µ–∞–ª—å–Ω–æ—Å—Ç–∏ –Ω—É–∂–Ω–æ —Ä–∞—Å–ø–æ–∑–Ω–∞–≤–∞–Ω–∏–µ –∫–æ–Ω–∫—Ä–µ—Ç–Ω—ã—Ö –±—É–∫–≤
        """
        # –ü–æ–∫–∞ –≤–æ–∑–≤—Ä–∞—â–∞–µ–º —Å–ª—É—á–∞–π–Ω—ã–µ –∑–Ω–∞—á–µ–Ω–∏—è –Ω–∞ –æ—Å–Ω–æ–≤–µ –æ–±—â–∏—Ö —Ö–∞—Ä–∞–∫—Ç–µ—Ä–∏—Å—Ç–∏–∫ –∏–∑–æ–±—Ä–∞–∂–µ–Ω–∏—è
        height, width = binary.shape
        text_density = self._calculate_density(binary)
        
        # –ì–µ–Ω–µ—Ä–∏—Ä—É–µ–º —Ö–∞—Ä–∞–∫—Ç–µ—Ä–∏—Å—Ç–∏–∫–∏ –Ω–∞ –æ—Å–Ω–æ–≤–µ —Å–≤–æ–π—Å—Ç–≤ –∏–∑–æ–±—Ä–∞–∂–µ–Ω–∏—è
        base_value = (height * width) % 100 / 100
        
        return CyrillicFeatures(
            ya_shape=0.5 + (text_density * base_value) % 0.4,
            zh_shape=0.6 + (width % 50) / 125,
            fi_shape=0.7 + (height % 30) / 100,
            shcha_shape=0.8 + (text_density * 100) % 20 / 100,
            yery_shape=0.5 + ((width + height) % 50) / 100
        )
    

    

    

    

    

    
# Fallback –º–µ—Ç–æ–¥—ã —É–¥–∞–ª–µ–Ω—ã - –∏—Å–ø–æ–ª—å–∑—É–µ–º —Ç–æ–ª—å–∫–æ PaddleOCR
    

    
# Fallback –º–µ—Ç–æ–¥—ã —É–¥–∞–ª–µ–Ω—ã - –∏—Å–ø–æ–ª—å–∑—É–µ–º —Ç–æ–ª—å–∫–æ PaddleOCR

